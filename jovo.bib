@article{Kutten2016,
abstract = {The CLARITY method renders brains optically transparent to enable high-resolution imaging in the structurally intact brain.  Anatomically annotating CLARITY brains is necessary for discovering which regions contain signals of interest. Manually annotating whole-brain, terabyte CLARITY images is difficult, time-consuming, subjective, and error-prone. Automatically registering CLARITY images to a pre-annotated brain atlas offers a solution, but is difficult for several reasons. Removal of the brain from the skull and subsequent storage and processing cause variable non-rigid deformations, thus compounding inter-subject anatomical variability. Additionally, the signal in CLARITY images arises from various biochemical contrast agents which only sparsely label brain structures. This sparse labeling challenges the most commonly used registration algorithms that need to match image histogram statistics to the more densely labeled histological brain atlases. The standard method is a multiscale Mutual Information B-spline algorithm that dynamically generates an average template as an intermediate registration target. We determined that this method performs poorly when registering CLARITY brains to the Allen Institute's Mouse Reference Atlas (ARA), because the image histogram statistics are poorly matched. Therefore, we developed a method (Mask-LDDMM) for registering CLARITY images, that automatically find the brain boundary and learns the optimal deformation between the brain and atlas masks. Using Mask-LDDMM without an average template provided better results than the standard approach when registering CLARITY brains to the ARA. The LDDMM pipelines developed here provide a fast automated way to anatomically annotate CLARITY images. Our code is available as open source software at \href{http://neurodata.io./}{this url}},
author = {Kutten, Kwame S. and Vogelstein, Joshua T. and Charon, Nicolas and Ye, Li and Deisseroth, Karl and Miller, Michael I.},
journal = {arXiv},
volume = {1605.02060},
title = {\href{http://arxiv.org/abs/1605.02060}{Deformably Registering and Annotating Whole CLARITY Brains to an Atlas via Masked LDDMM}},
year = {2016}
}
@article{Chen2016b, 
author={L. Chen and C. Shen and J. T. Vogelstein and C. E. Priebe}, 
journal={IEEE Transactions on Pattern Analysis and Machine Intelligence}, 
title={\href{http://dx.doi.org/10.1109/TPAMI.2015.2456913}{Robust Vertex Classification}}, 
year={2016}, 
volume={38}, 
number={3}, 
pages={578-590}, 
abstract={For random graphs distributed according to stochastic blockmodels, a special case of latent position graphs, adjacency spectral embedding followed by appropriate vertex classification is asymptotically Bayes optimal; but this approach requires knowledge of and critically depends on the model dimension. In this paper, we propose a sparse representation vertex classifier which does not require information about the model dimension. This classifier represents a test vertex as a sparse combination of the vertices in the training set and uses the recovered coefficients to classify the test vertex. We prove consistency of our proposed classifier for stochastic blockmodels, and demonstrate that the sparse representation classifier can predict vertex labels with higher accuracy than adjacency spectral embedding approaches via both simulation studies and real data experiments. Our results demonstrate the robustness and effectiveness of our proposed vertex classifier when the model dimension is unknown.}, 
keywords={Bayes methods;graph theory;pattern classification;adjacency spectral embedding approaches;asymptotically Bayes optimal vertex classification;latent position graphs;model dimension;random graphs;robust vertex classification;sparse representation vertex classifier;stochastic blockmodels;Analytical models;Biological system modeling;Contamination;Couplings;Eigenvalues and eigenfunctions;Robustness;Stochastic processes;Sparse representation;adjacency spectral embedding;classification consistency;latent position model;model dimension;robustness;sparse representation;stochastic blockmodel;vertex classification}, 
doi={10.1109/TPAMI.2015.2456913}, 
url={http://dx.doi.org/10.1109/TPAMI.2015.2456913}
ISSN={0162-8828}, 
month={March},}
@article {Raag2016,
author = {Airan, Raag D. and Vogelstein, Joshua T. and Pillai, Jay J. and Caffo, Brian and Pekar, James J. and Sair, Haris I.},
title = {\href{http://dx.doi.org/10.1002/hbm.23150}{Factors affecting characterization and localization of interindividual differences in functional connectivity using MRI}},
journal = {Human Brain Mapping},
issn = {1097-0193},
url = {http://dx.doi.org/10.1002/hbm.23150},
doi = {10.1002/hbm.23150},
keywords = {resting state fMRI, functional connectivity, subject-level differences},
year = {2016},
abstract = {
Much recent attention has been paid to quantifying anatomic and functional neuroimaging on the individual subject level. For optimal individual subject characterization, specific acquisition and analysis features need to be identified that maximize interindividual variability while concomitantly minimizing intra-subject variability. We delineate the effect of various acquisition parameters (length of acquisition, sampling frequency) and analysis methods (time course extraction, region of interest parcellation, and thresholding of connectivity-derived network graphs) on characterizing individual subject differentiation. We utilize a non-parametric statistical metric that quantifies the degree to which a parameter set allows this individual subject differentiation by both maximizing interindividual variance and minimizing intra-individual variance. We apply this metric to analysis of four publicly available test-retest resting-state fMRI (rs-fMRI) data sets. We find that for the question of maximizing individual differentiation, (i) for increasing sampling, there is a relative tradeoff between increased sampling frequency and increased acquisition time; (ii) for the sizes of the interrogated data sets, only 3-4 min of acquisition time was sufficient to maximally differentiate each subject with an algorithm that utilized no a priori information regarding subject identification; and (iii) brain regions that most contribute to this individual subject characterization lie in the default mode, attention, and executive control networks. These findings may guide optimal rs-fMRI experiment design and may elucidate the neural bases for subject-to-subject differences. Hum Brain Mapp, 2016. © 2016 Wiley Periodicals, Inc.
},
}
@article{Harris2015,
abstract={Resurgent interest in synaptic circuitry and plasticity has emphasized the importance of 3D reconstruction from serial section electron microscopy (3DEM). Three volumes of hippocampal CA1 neuropil from adult rat were imaged at X-Y resolution of ~2 nm on serial sections of ~50–60 nm thickness. These are the first densely reconstructed hippocampal volumes. All axons, dendrites, glia, and synapses were reconstructed in a cube (~10 μm3) surrounding a large dendritic spine, a cylinder (~43 μm3) surrounding an oblique dendritic segment (3.4 μm long), and a parallelepiped (~178 μm3) surrounding an apical dendritic segment (4.9 μm long). The data provide standards for identifying ultrastructural objects in 3DEM, realistic reconstructions for modeling biophysical properties of synaptic transmission, and a test bed for enhancing reconstruction tools. Representative synapses are quantified from varying section planes, and microtubules, polyribosomes, smooth endoplasmic reticulum, and endosomes are identified and reconstructed in a subset of dendrites. The original images, traces, and Reconstruct software and files are freely available and visualized at the Open Connectome Project},
title={\href{http://www.nature.com/articles/sdata201546}{A resource from 3D electron microscopy of hippocampal neuropil for user training and tool development}},
author={Harris, Kristen M and Spacek, Josef and Bell, Maria Elizabeth and Parker, Patrick H and Lindsey, Laurence F and Baden, Alexander D and Vogelstein, Joshua T and Burns, Randal},
journal={Scientific Data},
volume={2},
pages={150046},
doi={0.1038/sdata.2015.46},
year={2015}
}
@article{Narayanan2015,
abstract={We describe automated technologies to probe the structure of neural tissue at nanometer resolution and use them to generate a saturated reconstruction of a sub-volume of mouse neocortex in which all cellular objects (axons, dendrites, and glia) and many sub-cellular components (synapses, synaptic vesicles, spines, spine apparati, postsynaptic densities, and mitochondria) are rendered and itemized in a database. We explore these data to study physical properties of brain tissue. For example, by tracing the trajectories of all excitatory axons and noting their juxtapositions, both synaptic and non-synaptic, with every dendritic spine we refute the idea that physical proximity is sufficient to predict synaptic connectivity (the so-called Peters’ rule). This online minable database provides general access to the intrinsic complexity of the neocortex and enables further data-driven inquiries.},
title = {\href{http://www.cell.com/cell/abstract/S0092-8674(15)00824-7}{Saturated Reconstruction of a Small Volume of Neocortex}},
author = {Kasthuri, Narayanan and Hayworth, Kenneth Jeffrey and Berger, Daniel Raimund and Schalek, Richard Lee and Conchello, Jose Angel and Knowles-Barley, Seymour and Lee, Dongil and Vazquez-Reina and Kaynig, Verena and Jones, Thouis R and Roberts, Mike and Morgan, Josh L and Tapia, Juan Carlos and Seung, H Sebastian and Roncal, William Gray and Vogelstein, Joshua T and Burns, Randal and Sussman, Daniel L and Priebe, Carey E and Pfister, Hanspeter and Lichtman, Jeff W},
journal={Cell},
volume={162},
pages={648--661},
year={2015}
}
@misc{BrainWorkshop,
title = {\href{http://cra.org/ccc/wp-content/uploads/sites/2/2014/12/CCC-Brain-Workshop-Report.pdf}{A New Age of Computing and the Brain. In CCC Brain Workshop}},
author = {Golland, P and Galland, J and Hager, G and Pfister, H and Christos, P and Schaal, S and Vogelstein, J T},
year = {2015}
}
@misc{DunsCurr,
title = {{Robust Bayesian Inference via Lq-Likelihood}},
note = {Joint work with D.B. Dunson, Carey E. Priebe, Y. Qin}
}
@misc{MaggCurr,
title = {{Optimal Subspace Projection for High-Dimensional Classiciation and Testing}},
note = {Joint work with M. Maggioni}
}
@misc{PrieCurr,
title = {{Nonparametric Two-Sample Testing on Graph-Valued Populations}},
note = {Joint work with Carey E. Priebe}
}
@misc{ChenCurr,
title = {{Massive State Space learning and Inference}},
note = {Joint work with S. Chen, S. Lee, M Lindquist, B. Caffo}
}
@misc{GoldCurr,
title = {{Neuronal Classification from Network Connectivity}},
note = {Joint work with R. Goldin, D. Marchette, P. Salomonsky, Carey E. Priebe, G. Ascoli}
}
@misc{MarcCurr,
title = {{Class Morphing}},
note = {Joint work with D. Marchette, Carey E. Priebe}
}
@misc{GreeCurr,
title = {{Optimal Spike Inference from in vivo 2-Photon Calcium Imaging}},
note = {Joint work with D. Greenberg, J. Kerr}
}
@misc{SismCurr,
title = {{Extracting Priximity for Brain Graph Voxel Classification}},
note = {Joint work with N. Sismanis, D.L. Sussman, X. Sun, N. Pitsianis}
}
@misc{ConnUnp,
title = {{A Six Degree-Of-Freedom Two-Photon Microscope for Functional Imaging in Awake Behaving Primates}},
note = {Joint work with C.E. Connor et al}
}
@misc{YounUnp,
title = {{A Spiking Model of Ventral Cochlear Nucleus in Response to Complex Stimuli}},
note = {Joint work with E. Young},
year = {2004}
}
@misc{MoraUnp,
title = {{A Hardware Emulator of Awake Behaving Macaque Primary Motor Cortex}},
note = {Joing work with D. Moran},
year = {2003}
}
@inproceedings{Vogelstein2002,
author = {Vogelstein, Joshua T and Snyder, LH and Warchol, M and Angelaki, DE},
booktitle = {Society for Neuroscience},
title = {{Up-down asymmetry in memory guided saccadic eye movements are independent of head orientation in space}},
year = {2002}
}
@inproceedings{Vogelstein2004,
author = {Vogelstein, Joshua T and Zhang, K},
booktitle = {Society for Neuroscience},
title = {{A novel theory for simultaneous representation of multiple dynamic states in hippocampus}},
year = {2004}
}
@inproceedings{Vogelstein2007a,
author = {Vogelstein, Joshua T and Zhang, K and Jedynak, B and Paninski, L},
booktitle = {COSYNE},
title = {\href{http://dx.doi.org/10.6084/m9.figshare.1285828}{Maximum Likelihood Inference of Neural Dynamics under Noisy and Intermittent Observations using Sequential Monnte Carlo EM Algorithms}},
year = {2007}
}
@inproceedings{Vogelstein2008c,
author = {Vogelstein, Joshua T Babadi, B and Paninski, L},
booktitle = {COSYNE},
title = {\href{http://dx.doi.org/10.6084/m9.figshare.1285826}{Model-Based Optimal Inference of Spike-Times and Calcium Dynamics given Noisy and Intermittent Calcium-Fluorescence Imaging}},
year = {2008}
}
@inproceedings{Vogelstein2007b,
author = {Vogelstein, Joshua T and Jedynak, B and Zhang, K and Paninski, L},
booktitle = {Society for Neuroscience},
title = {\href{http://dx.doi.org/10.6084/m9.figshare.1285846}{Inferring Spike Trains, Neural Filters, and Network Circuits from in vivo Calcium Imaging}},
year = {2007}
}
@inproceedings{Vogelstein2008b,
author = {Vogenstein, Joshua T and Paninski, L},
booktitle = {Integrative Approaches to Brain Complexity},
title = {\href{http://dx.doi.org/10.6084/m9.figshare.1285827}{Inferring Spike Trains, Learning Tuning Curves, and Estimating Connectivity from Calcium Imaging}},
year = {2008}
}
@inproceedings{Vogelstein2008,
author = {Vogelstein, Joshua T and Paninski, L},
booktitle = {Statistical and Applied Mathematical Sciences Institute (SAMSI) Program on Sequential Monte Carlo Methods},
}
@inproceedings{Vogelstein2008,
author = {Vogelstein, Joshua T and Paninski, L},
booktitle = {Statistical and Applied Mathematical Sciences Institute (SAMSI) Program on Sequential Monte Carlo Methods},
title = {\href{http://dx.doi.org/10.6084/m9.figshare.1285825}{Spike Inference from Calcium Imaging using Sequential Monte Carlo Methods}},
year = {2008}
}
@inproceedings{Vogelstein2008a,
author = {Vogelstein, Joshua T and Babadi, B and Watson, BO and Yuste, R and Paninski, L},
booktitle = {Society for Neuroscience},
title = {\href{http://dx.doi.org/10.6084/m9.figshare.1285824}{From Calcium Sensitive Fluorescence Movies to Spike Trains}},
year = {2008}
}
@inproceedings{Vogelstein2009c,
author = {Vogelstein, Joshua T and Mishchenki, Y and Packer, AM and Machado, TA and Yuste, R and Paninski, L},
booktitle = {COSYNE},
title = {\href{http://dx.doi.org/10.6084/m9.figshare.1285821}{Towards Inferring Neural Circuit Inference from Population Calcium Imaging}},
year = {2009}
}
@inproceedings{Vogelstein2009a,
booktitle = {Society for Neuroscience},
author = {Vogelstein, Joshua T and Mishchchenko, Y and Packer, A M and Machado, T A and Yuste, R and Paninski, L},
title = {\href{http://dx.doi.org/10.6084/m9.figshare.1285823}{Towards Confirming Neural Circuits from Population Calcium Imaging}},
year = {2009}
}
@inproceedings{Vogelstein2009b,
booktitle = {NIPS Workshop on Workshop on Connectivity Infernence in Neuroimaging},
author = {Vogelstein, Joshua T and Mishchchenko, Y and Packer, A M and Machado, T A and Yuste, R and Paninski, L},
title = {\href{http://dx.doi.org/10.6084/m9.figshare.1285822}{Towards Confirming Neural Circuits from Population Calcium Imaging}},
year = {2009}
}
@inproceedings{Vogelstein2010a,
author = {Vogelstein, Joshua T and Mishchenki, Y and Packer, AM and Machado, TA and Yuste, R and Paninski, L},
booktitle = {COSYNE},
title = {\href{http://dx.doi.org/10.6084/m9.figshare.1284693}{Towards Confirming Neural Circuit Inference from Population Calcium Imaging}},
year = {2010}
}
@inproceedings{Vogelstein2010e,
author = {Vogelstein, Joshua T and Mishchenki, Y and Packer, AM and Machado, TA and Yuste, R and Paninski, L},
booktitle = {COSYNE},
title = {\href{http://dx.doi.org/10.6084/m9.figshare.1285819}{Towards Inferring Neural Circuit Inference from Population Calcium Imaging}},
year = {2010}
}
@inproceedings{Vogelstein2010b,
author = {Vogelstein, Joshua T and Vogelstein, RJ and Priebe, Carey E},
booktitle = {CSHL conference on Neural Circuits},
title = {\href{http://dx.doi.org/10.6084/m9.figshare.1284694}{A Neurocognitive Graph-Theoretical Approach to Understanding the Relationship Between Minds and Brains}},
year = {2010}
}
@inproceedings{Vogelstein2010c,
author = {Vogelstein, Joshua T and Bogovic, J and Carass, A and Gray, WR and Prince, JL and Landman, B and Pham, D and Ferrucci, L and Resnick, SM and Priebe, Carey E and Vogelstein, RJ},
booktitle = {Organization for Human Brain Mapping},
title = {\href{http://dx.doi.org/10.6084/m9.figshare.1285813}{Graph-Theoretical Methods for Statistical Inference on MR Connectome Data}},
year = {2010}
}
@inproceedings{Gray2010,
author = {Gray, William R and Vogelstein, Joshua T and Bogovic, J and Carass, A and Prince, J L and Landman, B and Pham, D and Ferrucci, L and Resnick, S M and Priebe, Carey E and Vogelstein, R Jacob},
booktitle = {DARPA Neural Engineering, Science and Technology Forum},
title = {\href{http://dx.doi.org/10.6084/m9.figshare.1285815}{Graph-Theoretical Methods for Statistical Inference on MR Connectome Data}},
year = {2010}
}
@inproceedings{Vogelstein2010d,
author = {Vogelstein, Joshua T and Priebe, Carey E and Burns, R and Vogelstein, R Jacob and Lichtman, J},
booktitle = {DARPA Neural Engineeering, Science and Technology Forum},
title = {\href{http://dx.doi.org/10.6084/m9.figshare.1285813}{Measuring and reconstructing the brain at the synaptic scale: towards a biofidelic human brain in silico}},
year = {2010}
}
@inproceedings{Gray2011,
author = {Gray, William R and Bogovic, J A and Vogelstein, Joshua T and Ye, C and Landman, B A and Prince, J L and Vogelstein, R Jacob},
booktitle = {Society for Neuroscience},
title = {\href{http://dx.doi.org/10.6084/m9.figshare.1284177}{Magnetic resonance connectome automated pipeline and repeatability analysis}},
year = {2011}
}
@inproceedings{Vogelstein2011d,
author = {Vogelstein, Joshua T and Gray, W and Martin, J G and Coppersmith, G C and Dredze, M and Bogovic, J and Prince, J L and Resnick, S M and Priebe, Carey E and Vogelstein, R J},
booktitle = {Society for Neuroscience},
title = {\href{http://dx.doi.org/10.6084/m9.figshare.1284178}{Connectome Classification using statistical graph theory and machine learning}},
year = {2011}
}
@inproceedings{Vogelstein2011h,
author = {Vogelstein, Joshua T and Gray, William R and Vogelstein, R Jacob and Bogovic, J and Resnick, S and Prince, J and Priebe, Carey E},
booktitle = {Organization for Human Brain Mapping},
title = {\href{http://dx.doi.org/10.6084/m9.figshare.1284179}{Connectome Classification: Statistical Graph Theoretic Methods for Analysis of MR-Connectome Data}},
year = {2011}
}
@article{Vogelstein2011e,
author = {Vogelstein, Joshua T and Perlman, E and Bock, D and Lee, W C and Chang, M and Kasthuri, B and Kazhdan, M and Reid, C and Lichtman, J and Burns, R and Vogelstein, R Jacob},
journal = {Neuroinformatics},
title = {\href{http://dx.doi.org/10.6084/m9.figshare.1284181}{Open Connectome Project: collectively reverse engineering the brain one synapse at a time}},
year = {2011}
}
@inproceedings{Vogelstein2011f,
author = {Vogelstein, Joshua T and Sussman, D L and Tang, M and Fishkind, D E and Priebe, Carey E},
booktitle = {IMA conference on Large Graphs},
title = {{Dot product embedding in large (errorfully observed) graphs with applications in statistical connectomics}},
year = {2011}
}
@inproceedings{Vogelstein2011g,
author = {Vogelstein, J T and Fishkind, D E and Sussman, D L and Priebe, C E},
booktitle = {IMA conference on Large Graphs},
title = {\href{http://dx.doi.org/10.6084/m9.figshare.1284184}{Large graph classification: theory and statistical connectomics applications}},
year = {2011}
}
@inproceedings{Vogelstein,
author = {Vogelstein, Joshua T and Vogelstein, R Jacob and Priebe, Carey E},
title = {\href{http://dx.doi.org/10.6084/m9.figshare.1284180}{Are Mental Properties Supervenient on Brain Properties?}}
}

@inproceedings{Vogelstein2012,
author = {Vogelstein, Joshua T and others},
booktitle = {Neuroinformatics},
title = {\href{http://dx.doi.org/10.6084/m9.figshare.1284173}{BRAINSTORM towards clinically and scientifically useful neuroimaging analytics}},
year = {2012}
}
@inproceedings{Vogelstein2012a,
author = {Vogelstein, Joshua T and others},
booktitle = {Janelia Farm conference, Statistical Inference and Neuroscience},
title = {\href{http://dx.doi.org/10.6084/m9.figshare.1284174}{Statistical Connectomics}},
year = {2012}
}
@inproceedings{Craddock2013a,
author = {Craddock, C and others},
booktitle = {OHBM},
title = {{Towards Automated Analysis of Connectomes: The Configurable Pipeline for the Analysis of Connectomes}},
year = {2013}
}
@inproceedings{Mhembere2013a,
author = {Mhembere, D and others},
title = {\href{http://dx.doi.org/10.6084/m9.figshare.1284154}{Multivariate Invariants from Massive Brain-Graphs}},
booktitle = {OHBM},
year = {2013}
}
@inproceedings{Airan2013,
author = {Airan, R D and Vogelstein, Joshua T and others},
booktitle = {Proc ISMRM},
pages = {1932},
title = {\href{http://dx.doi.org/10.6084/m9.figshare.1284146}{Reproducible differentiation of individual of individual subjects with minimal acquisition time via resting state fMRI}},
year = {2013}
}
@inproceedings{Pnevmatikakis2013,
author = {Pnevmatikakis, E A and others},
booktitle = {COSYNE},
title = {\href{http://dx.doi.org/10.6084/m9.figshare.1284170}{Rank-penalized nonnegative spatiotemporal deconvolution and demixing of calciu inaging data}},
year = {2013}
}
@inproceedings{Gray2013,
author = {Gray, William R and others},
booktitle = {OHBM},
title = {\href{http://dx.doi.org/10.6084/m9.figshare.1284151}{Towards a Fully Automatic Pipeline for Connectome Estimation from High-Resolution EM Data}},
year = {2013}
}
@inproceedings{Gray2012b,
author = {Gray, William R and others},
booktitle = {Cold Spring Harbor Laboratory, Neuronal Circuits},
title = {\href{http://dx.doi.org/10.6084/m9.figshare.1284176}{Towards a Fully Automatic Pipeline for Connectome Estimation from High-Resolution EM Data}},
year = {2012}
}
@inproceedings{Vogelstein2015a,
author = {Chen, Shaojie and Vogelstein, Joshua T and Lee, Seonjoo and Lindquist, Martin and Caffo, Brian},
booktitle = {ENAR 2015},
title = {\href{chrome-extension://oemmndcbldboiebfnladdacbdfmadadm/http://www.enar.org/abstracts/2015_Program_Abstracts_03-02-15.pdf}{High Dimensional State Space Model with L-1 and L-2 Penalties}},
year = {2015}
}
@inproceedings{_Nonparametric_2013,
author = {Vogenstein, Joshua T and Priebe, Carey E},
booktitle = {Duke Workshop on Sensing and Analysis of HighDimensional Data},
title = {{Nonparametric Two-Sample Testing on Graph-Valued Data.}},
year = {2013}
}
@article{Zheng2016,
    author={Zheng, Da and Mhembere, Disa and Vogelstein, Joshua T. and Priebe, Carey E. and Burns, Randal},
    title={\href{http://arxiv.org/abs/1604.06414v1}{FlashMatrix: Parallel, Scalable Data Analysis with Generalized Matrix Operations using Commodity SSDs}}, 
    year={2016},
    archivePrefix = {arXiv},
    arxivId = {1604.06414},
    journal = {arXiv},
    volume = {1604.06414},
    url={http://arxiv.org/abs/1604.06414v1},
    abstract={FlashMatrix is a matrix-oriented programming framework for general data analysis with high-level functional programming interface. It scales matrix operations beyond memory capacity by utilizing solid-state drives (SSDs) in non-uniform memory architecture (NUMA). It provides a small number of generalized matrix operations (GenOps) and reimplements a large number of matrix operations in the R framework with GenOps. As such, it executes R code in parallel and out of core automatically. FlashMatrix uses vectorized user-defined functions (VUDF) to reduce the overhead of function calls and fuses matrix operations to reduce data movement between CPU and SSDs. We implement multiple machine learning algorithms in R to benchmark the performance of FlashMatrix. On a large parallel machine, out-of-core execution of these R implementations in FlashMatrix has performance comparable to in-memory execution on a billion-scale dataset while significantly outperforming the in-memory implementations of Spark MLlib.}
    }
@inproceedings{Zheng2015,
author = {Zheng, Da and Mhembere, Disa and Burns, Randal and Vogenstein, Joshua T and Priebe, Carey E and Szalay, Alexander S},
booktitle = {USENIX Conference on File and Storage Technologies},
title = {\href{https://usenix.org/system/files/conference/fast15/fast15-paper-zheng.pdf}{FlashGraph: Processing Billion-Node Graphs on an Array of Commodity SSDs}},
year = {2015}
}
@inproceedings{Golland2015,
author= {Golland, Polina and Galland, Jack and Hager, Greg and Pfister, Hanspeter and Papadimitrious Christos and Schaal, Stefan and Vogelstein, Joshua T},
booktitle={CCC Brain Workshop},
title={\href{https://www.google.com/url?sa=t&rct=j&q=&esrc=s&source=web&cd=1&cad=rja&uact=8&ved=0CB8QFjAAahUKEwia4uyT6rrHAhWLGj4KHarRBhg&url=http%3A%2F%2Fcra.org%2Fccc%2Fwp-content%2Fuploads%2Fsites%2F2%2F2014%2F12%2FCCC-Brain-Workshop-Report.pdf&ei=KXHXVdqpLYu1-AGqo5vAAQ&usg=AFQjCNE1MUsQeT5sl59ZdHOyF4bvzhnkZw&sig2=c8oxClkiO8BnTmhKnp0D8w}{A New Age of Computing and the Brain}},
year={2015}
}
@inproceedings{Sismanis2013,
author = {Sismanis, N and others},
booktitle = {5th Panhellic Conference on Biomedical Technology},
title = {\href{http://dx.doi.org/10.6084/m9.figshare.1284143}{Feature Clustering from a Brain Graph for Voxel-to-Region Classification}},
year = {2013}
}
@inproceedings{Sussman2013,
author = {Sussman, D and others},
booktitle = {OHBM},
title = {\href{http://dx.doi.org/10.6084/m9.figshare.1284155}{Massive Diffusion MRI Graph Structure Preserves Spatial Information}},
year = {2013}
}
@inproceedings{Koutra2013a,
author = {Koutra, D and others},
booktitle = {OHBM},
title = {\href{http://dx.doi.org/10.6084/m9.figshare.1284149}{Are All Brains Wired Equally?}},
year = {2013}
}
@inproceedings{Qin2013a,
author = {Qin, Y and others},
booktitle = {OHBM},
title = {\href{http://dx.doi.org/10.6084/m9.figshare.1284153}{Robust Clustering of Adjacency Spectral Embeddings of Brain Graph Data via Lq-Likelihood}},
year = {2013}
}
@inproceedings{Vogelstein2013c,
author = {Vogelstein, Joshua T and others},
booktitle = {DARPA XDATA Colloquium},
title = {{Anomaly Screening and Clustering of Multi-OBject Movies via Multiscale Structure Learning}},
year = {2013}
}
@inproceedings{Vogelstein2013b,
author = {Vogelstein, Joshua T and Priebe, Carey E},
booktitle = {Duke Workshop on Sensing and Analysis of High-Dimensional Data},
title = {{Nonparametric Two-Sample Testing on Graph-Valued Data}},
year = {2013}
}
@inproceedings{Kulkarni2013,
author = {Kulkarni, V and Sastry, J and Vogelstein, Joshua T and Akoglu, L},
booktitle = {International Conference on Brain and Health Informatics},
note = {Lecture Notes in Computer Science, Volume 8211},
title = {\href{http://www.cs.stonybrook.edu/~leman/pubs/13bhi-sexdifferences.pdf}{Sex Differences in the Human Connectome}},
year = {2013}
}
@article{Airan,
author = {Airan, R and Vogelstein, Joshua T and Pillai, J J and Caffo, B and Pekar, J and Sair, H},
title = {\href{http://arxiv.org/abs/1508.05414}{Stability and localization of inter-individual differences in functional connectivity}},
journal = {arXiv},
volume = {1508.05414},
year = {2015}

}
@article{Chen2015B,
author = {Chen, Shaojie and Liu, Kai and Yang, Yuguang and Xu, Yuting and Lee, Seonjoo and Lindquist, Martin and Caffo, Brian S and Vogelstein, Joshua T},
abstract = {High-dimensional time-series data are becoming increasingly abundant across a wide variety of domains, spanning economics, neuroscience, particle physics, and cosmology. Fitting statistical models to such data, to enable parameter estimation and time-series prediction, is an important computational primitive. Existing methods, however, are unable to cope with the high-dimensional nature of these problems, due to both computational and statistical reasons. We mitigate both kinds of issues via proposing an M-estimator for Reduced-rank System IDentification (MR. SID). A combination of low-rank approximations, L-1 and L-2 penalties, and some numerical linear algebra tricks, yields an estimator that is computationally efficient and numerically stable. Simulations and real data examples demonstrate the utility of this approach in a variety of problems. In particular, we demonstrate that MR. SID can estimate spatial filters, connectivity graphs, and time-courses from native resolution functional magnetic resonance imaging data. Other applications and extensions are immediately available, as our approach is a generalization of the classical Kalman Filter-Smoother Expectation-Maximization algorithm.},
archivePrefix = {arXiv},
arxivId = {1509.03927},
title = {\href{http://arxiv.org/abs/1509.03927#}{An M-Estimator for Reduced-Rank High-Dimensional Linear Dynamical System Identification}},
journal = {arXiv},
volume = {1509.03927},
year = {2015}
}
@inproceedings{GrayRoncal2015a,
archivePrefix = {arXiv},
arxivId = {1403.3724},
author = {{Gray Roncal}, William and Pekala, Michael and Kaynig-fittkau,
Verena and Kleissas, Dean M and Vogelstein, Joshua T and Pfister, Hanspeter
and Burns, Randal and Vogelstein, R Jacob and Chevillet, Mark A and Hager,
Gregory D},
eprint = {1254329},
booktitle = {26th British Machine Vision Conference (BMVC)},
pages = {1--9},
primaryClass = {arXiv:submit},
title = {\href{http://bmvc2015.swansea.ac.uk/proceedings/papers/paper081/index.html}{VESICLE : Volumetric Evaluation of Synaptic Inferfaces using Computer vision at Large Scale}},
year = {2015}
}
@article{Vogelstein1999,
author = {Vogelstein, Joshua T and Vogelstein, R Jacob and B Vogelstein},
journal = {Science},
pages = {2300--2301},
title = {\href{http://www.sciencemag.org/content/286/5448/2300}{Testing the effects of genetic variations using MINIME technology}},
volume = {286},
year = {1999}
}
@article{Lyzinski2015,
author = {Lyzinski, Vince and Sussman, Daniel L and Fishkind, Donniell E and Pao, Henry and Chen, Li and Vogelstein, Joshua T and Park, Youngser and Priebe, Carey E},
abstract = {We present a parallelized bijective graph matching algorithm that leverages seeds and is designed to match very large graphs. Our algorithm combines spectral graph embedding with existing state-of-the-art seeded graph matching procedures. We justify our approach by proving that modestly correlated, large stochastic block model random graphs are correctly matched utilizing very few seeds through our divide-and-conquer procedure. We also demonstrate the effectiveness of our approach in matching very large graphs in simulated and real data examples, showing up to a factor of 8 improvement in runtime with minimal sacrifice in accuracy.},
title = {\href{http://www.sciencedirect.com/science/article/pii/S0167819115000484}{Spectral clustering for divide-and-conquer graph matching}},
journal = {Parallel Computing},
year = {2015},
volume={47},
pages={70--87},
doi = {10.1016},
}
@article{Weiler2014,
author = {Weiler, Nicholas C and Collman, Forrest and Vogelstein, Joshua T and Burns, Randal and Smith, Stephen J},
doi = {10.1038/sdata.2014.46},
issn = {2052-4463},
journal = {Scientific Data},
keywords = {Barrel cortex,Microscopy,Synaptic plasticity},
language = {en},
month = December,
pages = {140046},
publisher = {Nature Publishing Group},
title = {\href{http://www.nature.com/articles/sdata201446}{Synaptic molecular imaging in spared and deprived columns of mouse barrel cortex with array tomography}},
url = {http://www.nature.com/articles/sdata201446},
volume = {1},
year = {2014}
}
@inproceedings{Qin2013,
author = {Qin, Y},
booktitle = {OHBM},
title = {{Clustering of Adjacency Spectral Embeddings of Brain Graph Data via Lq-Likelihood}},
year = {2013}
}
@inproceedings{Vogelstein2013a,
author = {Vogelstein, Joshua T and Priebe, Carey E},
booktitle = {Duke Workshop on Sensing and Analysis of High-Dimensional Data},
title = {{Nonparametric Two-Sample Testing on Graph Valued Data.}},
year = {2013}
}
@article{Vogelstein2014,
author = {Vogelstein, Joshua and others},
title = {\href{http://dx.doi.org/10.6084/m9.figshare.1138318}{Anomaly Screening and Clustering of Multi-Object Movies via Multiscale Structure Learning}},
url = {http://dx.doi.org/10.6084/m9.figshare.1138318},
journal = {DARPA XDATA PI Meeting},
year = {2013}
}
@proceedings{BigNeu2,
address = {Theory and Neurobiology, Duke University},
title = {\href{http://dx.doi.org/10.6084/m9.figshare.1284175}{BIG NEURO}},
year = {2012}
}
@proceedings{WhaCanTra,
address = {Child Mind Institute},
title = {{What can Translational neuroimaging Research do for Clinical Practice}},
year = {2011}
}
@proceedings{ConClaSta,
address = {Organization for Human Brain Mapping},
title = {\href{http://dx.doi.org/10.6084/m9.figshare.1143153}{Connectome Classification: Statistical Graph Theoretic Methods for Analysis of MR-Connectome Data}},
year = {2011}
}
@proceedings{TowInfNeu,
address = {Guest Lecture in Yuste Lab},
title = {\href{http://dx.doi.org/10.6084/m9.figshare.1143384}{Towards Inferring Neural Circuits from Calcium Imaging}},
year = {2009}
}
@proceedings{StaInf2,
address = {University of Michigan},
title = {{Statistical Inference on Graphs}},
year = {2013}
}
@proceedings{StaInf3,
address = {Scientific Computing Institute, University of Utah},
title = {{Statistical Inference on Graphs}},
year = {2013}
}
@proceedings{ConConCla,
address = {Math/Bio Seminar, Duke University},
title = {\href{http://dx.doi.org/10.6084/m9.figshare.1143221}{Consistent Connectome Classification}},
year = {2011}
}
@proceedings{OpeProNeu,
address = {Data Seminar, Duke University},
title = {\href{http://dx.doi.org/10.6084/m9.figshare.1143084}{Open Problems in Neuropsychiatry}},
year = {2013}
}
@proceedings{OncConWha,
address = {Krasnow Institute for Advanced Study at George Mason Univeristy},
title = {{Once we get connectomes, what the \%\#* are we going to do with them?}},
year = {2011}
}
@proceedings{OncGetCon,
address = {Institute of Neuroinformatics},
title = {{Once we get connectomes, what the \%\#* are we going to do with them?}},
year = {2011}
}
@proceedings{NeuGraThe,
address = {national Security Agency},
title = {\href{http://dx.doi.org/10.6084/m9.figshare.1143358}{Neurocognitive Graph Theory}},
year = {2009}
}
@proceedings{OpeConPro,
address = {Academic Medical Center, Amsterdam},
title = {{Open Connectome Project}},
year = {2012}
}
@proceedings{BeyLitNeu,
address = {Beyond Optogenetics workshop at Cosyne},
title = {\href{http://dx.doi.org/10.6084/m9.figshare.1284169}{Beyond Little Neuroscience}},
year = {2013}
}
@proceedings{InfSpiTra,
address = {Statistical Analysis of Neural Data},
title = {{Inferring Spike Trains Given Calcium-Sensitive Fluorescence Observations}},
year = {2008}
}
@proceedings{AreMenPro,
organization = {NIPS workshop on Philosophy and Machine Learning},
title = {\href{http://dx.doi.org/10.6084/m9.figshare.1284180}{Are mental properties supervenient on brain properties}},
year = {2011}
}
@inproceedings{JovoSimA,
address = {DARPA SIMPLEX PI Meeting},
title = {\href{http://dx.doi.org/10.6084/m9.figshare.1593271}{From RAGs to Riches: Utilizing Richly Attributed Graphs to Reason from Heterogeneous Data: Part 1}},
year = {2015}
}
@inproceedings{JovoSimB,
address = {DARPA SIMPLEX PI Meeting},
title = {\href{http://dx.doi.org/10.6084/m9.figshare.1593272}{From RAGs to Riches: Utilizing Richly Attributed Graphs to Reason from Heterogeneous Data: Part 2}},
year = {2015}
}
@inproceedings{JanHighRes16,
author = {Vogelstein, Joshua T},
booktitle = {Janelia: High-Resolution Circuit Reconstruction},
title = {\href{http://docs.neurodata.io/ndintro/}{NeuroData: Enabling Terascale Neuroscience for Everyone}},
year = {2016}
}
@proceedings{KeyStateBrain,
address={Keystone Symposia: State of the Brain},
year={2016},
title={\href{http://docs.neurodata.io/ndintro/}{NeuroData: Enabling Terascale Neuroscience for Everyone}}
}
@proceedings{KeyStateBrain,
address={Keystone Symposia: State of the Brain},
year={2016},
title={\href{http://docs.neurodata.io/ndintro/}{NeuroData: Enabling Terascale Neuroscience for Everyone}}
}
@proceedings{OpeChaBig,
address={DoE},
year={2015},
title={\href{http://dx.doi.org/10.6084/m9.figshare.1515880}{Opportunities and Challenges in Big Data Neuroscience}}
}
@proceedings{FroRagRic,
address={SIMPLEX Kickoff},
year={2015},
title={\href{http://dx.doi.org/10.6084/m9.figshare.1515878}{From RAGs to Riches: Utilizing Richly Attributed Graphs to Reason from Heterogeneous Data}}
}
@proceedings{LawLarGra,
address={DARPA Graphs},
year={2015},
title={\href{http://dx.doi.org/10.6084/m9.figshare.1515877}{Law of Large Graphs}}
}
@proceedings{LowBarEnt,
address={Institute for Computational Medicine at Johns Hopkins University},
year={2015},
title={\href{http://dx.doi.org/10.6084/m9.figshare.1515876}{Open Connectome Project: Lowering the Barrier to Entry of Big Data Neuroscience}}
}
@proceedings{KavSpeSymp,
address={Kavli},
year={2015},
title={\href{http://www.kavlifoundation.org/special-symposium-neuroscience-21st-century}{Kavli Special Symposium: Neuroscience in the 21st Century}}
}
@proceedings{CasC,
address={CASC},
year={2015},
title={\href{http://casc.org/meetings/15oct/CASC%20Agenda%20Fall%202015.pdf}{Research Computing Support for Neuroscience and Other Life Sciences}}
}
@proceedings{DatIntBra,
address={Kavli},
year={2015},
title={\href{http://dx.doi.org/10.6084/m9.figshare.1515875}{Data Intensive Brain Sciences}}
}
@proceedings{OpeSouPla,
address = {Kavli},
year = {2014},
title = {\href{http://dx.doi.org/10.6084/m9.figshare.1381926}{Open-Science Platform for Heterogeneous Brain Data: Opportunities and Challenges}}
}
@proceedings{BigNeuSta,
publisher = {Big Data: Practice Across Disciplines}, 
address = {Kavli Salon},
year = {2014},
title = {\href{http://figshare.com/articles/Big\_Neuro\_Statistics/1142907}{Big (Neuro) Statistics}},
url = {http://figshare.com/articles/Big\_Neuro\_Statistics/1142907}
}
@proceedings{ModBasOpt,
address = {Neurotheory Center of Columbia University},
title = {{Model based optimal inference of spike times and calcium dynamics givern noisy and intermittent calcium-fluorescence observations}},
year = {2007}
}
@proceedings{TowInfAna,
address = {Guest Lecture in Schnitzer Lab},
title = {\href{http://dx.doi.org/10.6084/m9.figshare.1143326}{Towards Inference and Analaysis of Neural Circuits Inferred from Population Calcium Imaging}},
year = {2009}
}
@proceedings{InfSpiTraCI,
address = {Redwood Center for Theoretical Neuroscience, University of California, Berkeley},
title = {\href{http://dx.doi.org/10.6084/m9.figshare.1143426}{Inferring spike trains from Calcium Imaging}},
year = {2008}
}
@proceedings{DecTheApp,
address = {guest Lecture in Current Topics in Machine Learning, Johns Hopkins University},
title = {{Decision Theoretic Approach to Statistical Inference}},
year = {2012}
}
@proceedings{ConsGraCla,
address = {Guest Lecture in Deisseroth Lab, Stanford University},
title = {\href{http://dx.doi.org/10.6084/m9.figshare.1143129}{Consistent Graph Classification}},
year = {2011}
}
@proceedings{SeqMonCar,
address = {SAMSI Program on Sequential Monte Carlo, Tracking Working Group},
title = {{Sequential Monte Carlo in Neuroscience}},
year = {2009}
}
@article{Koutra2014,
author = {Koutra, D and Shah, N and Vogelstein, J T and Gallagher, B J and Faloutsos, C},
title = {\href{https://www.researchgate.net/publication/236203764_DELTACON_A_Principled_Massive-Graph_Similarity_Function}{DeltaCon: A Principled Massive-Graph Similarity Function}},
journal = {ACM Transactions on Knowledge Discovery from Data},
volume = {V},
number = {N},
year = {2014}
}
@proceedings{InfSpiTim,
address = {Department of Applied Mathematics and Statistics, Johns Hopkins University},
title = {\href{http://dx.doi.org/10.6084/m9.figshare.1143449}{Inferring spike times given typical time-series fluorescence observations}},
year = {2008}
}
@proceedings{StaCon,
address = {Harvard University Connectomics Labs},
title = {\href{http://dx.doi.org/10.6084/m9.figshare.1143276}{Statistical Connectomics}},
year = {2011}
}
@proceedings{StaModInf,
address = {NIPS Workshop on Acquiring and analyzing the activity of large neural ensembles},
title = {\href{http://dx.doi.org/10.6084/m9.figshare.1142993}{Statistical Models and Inference for big Brain-Graphs}},
year = {2013}
}
@proceedings{OopFamOpt,
address = {Dissertation Defense},
title = {\href{https://www.researchgate.net/publication/45657467\_OOPSI\_A\_family\_of\_optimal\_optical\_spike\_inference\_algorithms\_for\_inferring\_neural\_connectivity\_from\_population\_calcium\_imaging}{OOPSI: A Family of Optimal OPtical Spike Inference Algorithms for Inferring Neural Connectivity from Population Calcium Imaging}},
url = {https://www.researchgate.net/publication/45657467\_OOPSI\_A\_family\_of\_optimal\_optical\_spike\_inference\_algorithms\_for\_inferring\_neural\_connectivity\_from\_population\_calcium\_imaging},
year = {2009}
}
@proceedings{BigStaBra,
title = {\href{http://dx.doi.org/10.6084/m9.figshare.1140321}{Big Statistics for Brain Sciences}},
month = {May},
year = {2014},
address = {Baylor College of Medicine, Department of Neuroscience}
}

@proceedings{InfSpiTraCI2,
address = {Cambridge University, Gatsby Unit, and University College London},
title = {\href{http://dx.doi.org/10.6084/m9.figshare.1284091}{Inferring spike trains from Calcium Imaging}},
year = {2008}
}
@proceedings{TopChaBig,
address = {BRAIN Initiative Workshop},
title = {\href{http://dx.doi.org/10.6084/m9.figshare.1381888}{Top Challenges of Big Data Neuroscience}},
month = {Dec},
year = {2014}
}
@article{Chen2015,
abstract = {We investigate joint graph inference for the chemical and electrical connectomes of the \textit{Caenorhabditis elegans} roundworm. The \textit{C.elegans} connectomes consist of 253 non-isolated neurons with known functional attributes, and there are two types of synaptic connectomes, resulting in a pair of graphs. We formulate our joint graph inference from the perspectives of seeded graph matching and joint vertex classification. Our results suggest that connectomic inference should proceed in the joint space of the two connectomes, which has significant neuroscientific implications.},
journal = {Worm},
doi = {10.1080/21624054.2016.1142041},
URL = {http://dx.doi.org/10.1080/21624054.2016.1142041},
eprint = {http://dx.doi.org/10.1080/21624054.2016.1142041},
author={Chen, Li and Vogelstein, Joshua T and Lyzinski, Vince and Priebe, Carey E},
title={\href{http://dx.doi.org/10.1080/21624054.2016.1142041}{A Joint Graph Inference Case Study: the C. Elegans Chemical and Electrical Connectomes}},
journal={Worm},
year={2016}
}
@article{Roncal2015b,
abstract={Reconstructing a map of neuronal connectivity is a critical challenge in contemporary neuroscience. Recent advances in high-throughput serial section electron microscopy (EM) have produced massive 3D image volumes of nanoscale brain tissue for the first time. The resolution of EM allows for individual neurons and their synaptic connections to be directly observed. Recovering neuronal networks by manually tracing each neuronal process at this scale is unmanageable, and therefore researchers are developing automated image processing modules. Thus far, state-of-the-art algorithms focus only on the solution to a particular task (e.g., neuron segmentation or synapse identification). 
In this manuscript we present the first fully automated images-to-graphs pipeline (i.e., a pipeline that begins with an imaged volume of neural tissue and produces a brain graph without any human interaction). To evaluate overall performance and select the best parameters and methods, we also develop a metric to assess the quality of the output graphs. We evaluate a set of algorithms and parameters, searching possible operating points to identify the best available brain graph for our assessment metric. Finally, we deploy a reference end-to-end version of the pipeline on a large, publicly available data set. This provides a baseline result and framework for community analysis and future algorithm development and testing. All code and data derivatives have been made publicly available toward eventually unlocking new biofidelic computational primitives and understanding of neuropathologies.},
archivePrefix = {arXiv},
arxivId = {1411.6880},
author = {Roncal, William Gray and Kleissas, Dean M. and Vogelstein, Joshua T. and Manavalan, Priya and Burns, Randal and Vogelstein, R. Jacob and Priebe, Carey E. and Chevillet, Mark A. and Hager, Gregory D.},
eprint = {1411.6880},
volume=9,
issue=20,
doi={10.3389/fninf.2015.00020},
title = {\href{http://journal.frontiersin.org/article/10.3389/fninf.2015.00020/abstract}{An Automated Images-to-Graphs Pipeline for High Resolution Connectomics}},
journal = {Frontiers in Neuroinformatics},
url = {http://journal.frontiersin.org/article/10.3389/fninf.2015.00020/abstract},
year = {2015}
}
@article{Vogelstein2011c,
abstract = {Although it has been over a century since neuroscientists first conjectured that networks of neurons comprise the brain, technology has limited high-throughput investigations of neural circuitry until very recently. In the last couple of decades, several experimental paradigms have arisen that are poised to finally begin studying neuroanatomy in a high-throughput fashion. In 2005, the term connectome was coined independently by Patric Hagmann and Olaf Sporns, to describe the complete set of neural connections in a brain. Interestingly, both usages seemed to be referring to using Magnetic Resonance Imaging (MRI) to study human brain networks. Shortly thereafter, Narayanan "Bobby" Kasthuri and Jeff Lichtman published an article suggesting that "connectome" should refer to connections between neurons, which one can infer using Electron Microscopy (EM) and fluorescence microscopy (e.g., brainbow animals). "Projectome", they suggested, is more appropriate for MRI based studies. Yet, the word connectome stuck, and now refers to essentially any neuroscientific investigation of the relationship between (collections of) neurons, be they functional or structural.},
author = {Vogelstein, Joshua T},
doi = {10.1186/2042-1001-1-16},
isbn = {10.1186/2042-1001-1-16},
issn = {2042-1001},
journal = {Neural Systems \& Circuits},
language = {en},
pages = {16},
pmid = {22329952},
publisher = {BioMed Central Ltd},
title = {\href{https://www.researchgate.net/publication/221828234\_QA\_What\_is\_the\_Open\_Connectome\_Project}{Q\&A: What is the Open Connectome Project?}},
url = {https://www.researchgate.net/publication/221828234\_QA\_What\_is\_the\_Open\_Connectome\_Project},
volume = {1},
year = {2011}
}
@article{Yuste2011,
abstract = {The understanding of neuronal circuits has been greatly advanced by the ability to simultaneously image action-potential generation within large populations of neurons. This protocol describes bulk loading of brain slices with acetoxymethyl (AM) ester calcium indicators to monitor action-potential activity in functional neuronal circuits. The imaging of calcium influx into neurons provides an indirect but accurate measure of action-potential generation within individual neurons. The key advantage of the technique is that it allows the researcher to densely sample the activity of a large population of neurons with single-cell resolution.},
author = {Yuste, Rafael and MacLean, Jason and Vogelstein, Joshua and Paninski, Liam},
doi = {10.1101/pdb.prot5650},
issn = {1559-6095},
journal = {Cold Spring Harbor Protocols},
keywords = {Action Potentials,Calcium,Calcium: analysis,Cytological Techniques,Cytological Techniques: methods,Indicators and Reagents,Indicators and Reagents: metabolism,Neurons,Neurons: metabolism,Neurons: physiology},
number = {8},
pages = {985--9},
pmid = {21807854},
title = {\href{https://www.researchgate.net/publication/51539059\_Imaging\_action\_potentials\_with\_calcium\_indicators}{Imaging action potentials with calcium indicators.}},
url = {https://www.researchgate.net/publication/51539059\_Imaging\_action\_potentials\_with\_calcium\_indicators},
volume = {2011},
year = {2011}
}
@article{Vogelstein2013,
abstract = {This manuscript considers the following "graph classification" question: Given a collection of graphs and associated classes, how can one predict the class of a newly observed graph? To address this question, we propose a statistical model for graph/class pairs. This model naturally leads to a set of estimators to identify the class-conditional signal, or "signal-subgraph," defined as the collection of edges that are probabilistically different between the classes. The estimators admit classifiers which are asymptotically optimal and efficient, but which differ by their assumption about the "coherency" of the signal-subgraph (coherency is the extent to which the signal-edges "stick together" around a common subset of vertices). Via simulation, the best estimator is shown to be not just a function of the coherency of the model, but also the number of training samples. These estimators are employed to address a contemporary neuroscience question: Can we classify "connectomes" (brain-graphs) according to sex? The answer is yes, and significantly better than all benchmark algorithms considered. Synthetic data analysis demonstrates that even when the model is correct, given the relatively small number of training samples, the estimated signal-subgraph should be taken with a grain of salt. We conclude by discussing several possible extensions.},
author = {Vogelstein, Joshua T and Gray, William R and Vogelstein, R Jacob and Priebe, Carey E},
doi = {10.1109/TPAMI.2012.235},
issn = {1939-3539},
journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
keywords = {Algorithms,Automated,Automated: methods,Computer Simulation,Imaging,Models,Pattern Recognition,Reproducibility of Results,Statistical,Theoretical,Three-Dimensional,Three-Dimensional: methods},
language = {English},
number = {7},
pages = {1539--51},
pmid = {23681985},
publisher = {IEEE Computer Society},
title = {\href{http://arxiv.org/abs/1108.1427}{Graph classification using signal-subgraphs: applications in statistical connectomics.}},
url = {Subgraphs\_Applications\_in\_Statistical\_Connectomics},
volume = {35},
year = {2013}
}
@article{Huys2009,
author = {Huys, Quentin J. and Vogelstein, Joshua and Dayan, Peter},
journal = {Advances in Neural Information Processing Systems (NIPS)},
file = {:C$\backslash$:/Users/ericwb/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Huys, Vogelstein, Dayan - 2009 - Psychiatry Insights into depression through normative decision-making models.pdf:pdf},
pages = {729--736},
title = {\href{https://www.researchgate.net/publication/221618753\_Psychiatry\_Insights\_into\_depression\_through\_normative\_decision-making\_models}{Psychiatry: Insights into depression through normative decision-making models}},
url = {https://www.researchgate.net/publication/221618753\_Psychiatry\_Insights\_into\_depression\_through\_normative\_decision-making\_models},
year = {2008}
}
@article{Cornelis2013,
archivePrefix = {arXiv},
arxivId = {1304.5894},
author = {Cornelis, Bruno and Yang, Yun and Vogelstein, Joshua T and Dooms, Ann and Daubechies, Ingrid and Dunson, David},
eprint = {1304.5894},
title = {\href{http://arxiv.org/abs/1304.5894}{Bayesian crack detection in ultra high resolution multimodal images of paintings}},
url = {http://arxiv.org/abs/1304.5894},
year = {2013},
journal = {DSP 2013 Special Session on Tensor Factorization and its Applications}
}
@article{Koutra2013,
archivePrefix = {arXiv},
arxivId = {1304.4657},
author = {Koutra, D and Vogelstein, Joshua T and Faloutsos, C},
title = {\href{http://arxiv.org/abs/1304.4657}{DELTACON: Measuring Connectivity Differences in large networks}},
url = {http://arxiv.org/abs/1304.4657},
journal = {SIAM International Conference on Data Mining},
year = {2013},
volume = {Article No. 27}
},
@article{Burns2013,
archivePrefix = {arXiv},
arxivId = {1306.3543},
author = {Burns, Randal and Roncal, William Gray and Kleissas, Dean and Lillaney, Kunal and Manavalan, Priya and Perlman, Eric and Berger, Daniel R. and Bock, Davi D. and Chung, Kwanghun and Grosenick, Logan and Kasthuri, Narayanan and Weiler, Nicholas C. and Deisseroth, Karl and Kazhdan, Michael and Lichtman, Jeff and Reid, R. Clay and Smith, Stephen J. and Szalay, Alexander S. and Vogelstein, Joshua T. and Vogelstein, R. Jacob},
eprint = {1306.3543},
title = {\href{http://arxiv.org/abs/1306.3543}{The Open Connectome Project Data Cluster: Scalable Analysis and Vision for High-Throughput Neuroscience}},
url = {http://arxiv.org/abs/1306.3543},
journal = {Proceedings of the 25th International Conference on Scientific and Statistical Database Management (SSDBM)},
note = {Article No. 27, 2013}
}
@article{Burns2014,
abstract = {The analysis of data requires computation: originally by hand and more recently by computers. Different models of computing are designed and optimized for different kinds of data. In data-intensive science, the scale and complexity of data exceeds the comfort zone of local data stores on scientific workstations. Thus, cloud computing emerges as the preeminent model, utilizing data centers and high-performance clusters, enabling remote users to access and query subsets of the data efficiently. We examine how data-intensive computational systems originally built for cosmology, the Sloan Digital Sky Survey (SDSS), are now being used in connectomics, at the Open Connectome Project. We list lessons learned and outline the top challenges we expect to face. Success in computational connectomics would drastically reduce the time between idea and discovery, as SDSS did in cosmology.},
author = {Burns, Randal and Vogelstein, Joshua T and Szalay, Alexander S},
doi = {10.1016/j.neuron.2014.08.045},
file = {:C$\backslash$:/Users/ericwb/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Burns, Vogelstein, Szalay - 2014 - From cosmos to connectomes the evolution of data-intensive science.pdf:pdf},
issn = {1097-4199},
journal = {Neuron},
number = {6},
pages = {1249--52},
pmid = {25233306},
title = {\href{http://www.sciencedirect.com/science/article/pii/S0896627314007466}{From cosmos to connectomes: the evolution of data-intensive science.}},
url = {http://www.sciencedirect.com/science/article/pii/S0896627314007466},
volume = {83},
year = {2014}
}
@article{Mhembere2013,
archivePrefix = {arXiv},
arxivId = {1312.4318},
author = {Mhembere, Disa and Roncal, William Gray and Sussman, Daniel and Priebe, Carey E. and Jung, Rex and Ryman, Sephira and Vogelstein, R. Jacob and Vogelstein, Joshua T. and Burns, Randal},
eprint = {1312.4318},
title = {\href{http://arxiv.org/abs/1312.4318}{Computing Scalable Multivariate Glocal Invariants of Large (Brain-) Graphs}},
url = {http://arxiv.org/abs/1312.4318},
year = {2013},
journal = {GlobalSIP}
}
@article{Roncal2013,
archivePrefix = {arXiv},
arxivId = {1312.4875},
author = {Roncal, William Gray and Koterba, Zachary H. and Mhembere, Disa and Kleissas, Dean M. and Vogelstein, Joshua T. and Burns, Randal and Bowles, Anita R. and Donavos, Dimitrios K. and Ryman, Sephira and Jung, Rex E. and Wu, Lei and Calhoun, Vince and Vogelstein, R. Jacob},
eprint = {1312.4875},
title = {\href{http://arxiv.org/abs/1312.4875}{MIGRAINE: MRI Graph Reliability Analysis and Inference for Connectomics}},
url = {http://arxiv.org/abs/1312.4875},
year = {2013},
journal = {GlobalSIP}

}
@article{Fiori2013,
author = {Fiori, Marcelo and Sprechmann, Pablo and Vogelstein, Joshua and Muse, Pablo and Sapiro, Guillermo},
journal = {Advances in Neural Information Processing Systems (NIPS)},
file = {:C$\backslash$:/Users/ericwb/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Fiori et al. - 2013 - Robust Multimodal Graph Matching Sparse Coding Meets Graph Matching.pdf:pdf},
pages = {127--135},
title = {\href{https://www.researchgate.net/publication/258849948\_Robust\_Multimodal\_Graph\_Matching\_Sparse\_Coding\_Meets\_Graph\_Matching?ev=prf\_pub}{Robust Multimodal Graph Matching: Sparse Coding Meets Graph Matching}},
url = {https://www.researchgate.net/publication/258849948\_Robust\_Multimodal\_Graph\_Matching\_Sparse\_Coding\_Meets\_Graph\_Matching?ev=prf\_pub},
year = {2013},
note = {(spotlight)}
}
@article{Binkiewicz2014,
archivePrefix = {arXiv},
arxivId = {1411.2158},
author = {Binkiewicz, Norbert and Vogelstein, Joshua T. and Rohe, Karl},
eprint = {1411.2158},
journal={arXiv},
title = {\href{http://arxiv.org/abs/1411.2158}{Covariate Assisted Spectral Clustering}},
url = {http://arxiv.org/abs/1411.2158},
year = {2014}
}
@article{Carlson2013a,
author = {Carlson, David and Rao, Vinayak and Vogelstein, Joshua T. and Carin, Lawrence},
journal = {Advances in Neural Information Processing Systems (NIPS)},
pages = {2805--2813},
title = {\href{http://papers.nips.cc/paper/5061-real-time-inference-for-a-gamma-process-model-of-neural-spiking}{Real-Time Inference for a Gamma Process Model of Neural Spiking}},
url = {http://papers.nips.cc/paper/5061-real-time-inference-for-a-gamma-process-model-of-neural-spiking},
year = {2013}
}
@article{Petralia2013,
author = {Petralia, Francesca and Vogelstein, Joshua T. and Dunson, David},
booktitle = {Advances in Neural Information Processing Systems},
pages = {1797--1805},
title = {\href{https://www.researchgate.net/publication/259106327\_Multiscale\_Dictionary\_Learning\_for\_Estimating\_Conditional\_Distributions?ev=prf\_pub}{Multiscale Dictionary Learning for Estimating Conditional Distributions}},
url = {https://www.researchgate.net/publication/259106327\_Multiscale\_Dictionary\_Learning\_for\_Estimating\_Conditional\_Distributions?ev=prf\_pub},
journal = {Advances in Neural Information Processing Systems (NIPS)},
year = {2013}
}
@article{Greenspan1997,
abstract = {Allelic deletions involving the short arm of chromosome 3 (3p13-21.1) have been observed frequently in cervical carcinomas. Recently, a candidate tumor suppressor gene, FHIT (Fragile Histidine Triad), was cloned and mapped to this chromosomal region (3p14.2). Abnormal FHIT transcripts have been identified previously in a variety of tumor cell lines and primary carcinomas, although their significance and the molecular mechanisms underlying their origin remain incompletely defined. In addition, integration of human papillomavirus DNA has been identified at a fragile site (FRA3B) within the FHIT locus in cervical cancer. These observations motivated us to evaluate FHIT mRNA and protein expression in cervical cancer cell lines, primary cervical carcinomas, and normal tissues. Transcripts of the expected size and sequence were the predominant species identified by reverse transcription (RT)-PCR in cultured keratinocytes and all normal tissues evaluated. In contrast, aberrant FHIT transcripts were readily demonstrated in 6 of 7 cervical carcinoma cell lines and 17 of 25 (68\%) primary cervical carcinomas. Northern blot analyses demonstrated reduced or absent FHIT expression in the cervical carcinoma cell lines, particularly those with aberrant RT-PCR products. Immunohistochemical analysis of Fhit expression in cervical tissues revealed strong immunoreactivity in nonneoplastic squamous and glandular cervical epithelium and marked reduction or loss of Fhit protein in 25 of 33 (76\%) primary cervical carcinomas. In those cervical cancer cell lines and primary tumors with exclusively aberrant or absent FHIT transcripts by RT-PCR, Fhit protein expression was always markedly reduced or absent. The frequent alterations in FHIT expression in many cervical carcinomas, but not in normal tissues, suggest that FHIT gene alterations may play an important role in cervical tumorigenesis.},
author = {Greenspan, D L and Connolly, D C and Wu, R and Lei, R Y and Vogelstein, J T and Kim, Y T and Mok, J E and Mu\~{n}oz, N and Bosch, F X and Shah, K and Cho, K R},
issn = {0008-5472},
journal = {Cancer research},
keywords = {Acid Anhydride Hydrolases,Carcinoma,Carcinoma: genetics,Carcinoma: metabolism,Chromosomes,Complementary,Complementary: analysis,Cultured,DNA,Female,Gene Deletion,Genes,HeLa Cells,Human,Humans,Messenger,Messenger: metabolism,Neoplasm Proteins,Pair 3,Pair 3: genetics,Polymerase Chain Reaction,Proteins,Proteins: genetics,Proteins: metabolism,RNA,Sequence Analysis,Tumor Cells,Tumor Suppressor,Tumor Suppressor: genetics,Uterine Cervical Neoplasms,Uterine Cervical Neoplasms: genetics,Uterine Cervical Neoplasms: metabolism},
number = {21},
pages = {4692--8},
pmid = {9354423},
title = {\href{https://www.researchgate.net/publication/13875948\_Loss\_of\_FHIT\_expression\_in\_cervical\_carcinoma\_cell\_lines\_and\_primary\_tumors?ev=prf\_pub}{Loss of FHIT expression in cervical carcinoma cell lines and primary tumors.}},
url = {https://www.researchgate.net/publication/13875948\_Loss\_of\_FHIT\_expression\_in\_cervical\_carcinoma\_cell\_lines\_and\_primary\_tumors?ev=prf\_pub},
volume = {57},
year = {1997}
}
@article{Vogelstein2003,
author = {Vogelstein, Joshua T and Angelaki, D and Snyder, L},
journal = {Journal of Neurophysiology},
keywords = {Animals,Macaca mulatta,Memory,Memory: physiology,Orientation,Orientation: physiology,Posture,Posture: physiology,Saccades,Saccades: physiology},
number = {1},
pages = {521--4},
pmid = {12843314},
title = {\href{https://www.researchgate.net/publication/10676961\_Accuracy\_of\_saccades\_to\_remembered\_targets\_as\_a\_function\_of\_body\_orientation\_in\_space}{Accuracy of saccades to remembered targets as a function of body orientation in space.}},
url = {https://www.researchgate.net/publication/10676961\_Accuracy\_of\_saccades\_to\_remembered\_targets\_as\_a\_function\_of\_body\_orientation\_in\_space},
volume = {90},
year = {2003}
}
@article{Vogelstein2007,
abstract = {A mixed-signal very large scale integration (VLSI) chip for large scale emulation of spiking neural networks is presented. The chip contains 2400 silicon neurons with fully programmable and reconfigurable synaptic connectivity. Each neuron implements a discrete-time model of a single-compartment cell. The model allows for analog membrane dynamics and an arbitrary number of synaptic connections, each with tunable conductance and reversal potential. The array of silicon neurons functions as an address-event (AE) transceiver, with incoming and outgoing spikes communicated over an asynchronous event-driven digital bus. Address encoding and conflict resolution of spiking events are implemented via a randomized arbitration scheme that ensures balanced servicing of event requests across the array. Routing of events is implemented externally using dynamically programmable random-access memory that stores a postsynaptic address, the conductance, and the reversal potential of each synaptic connection. Here, we describe the silicon neuron circuits, present experimental data characterizing the 3 mm x 3 mm chip fabricated in 0.5-microm complementary metal-oxide-semiconductor (CMOS) technology, and demonstrate its utility by configuring the hardware to emulate a model of attractor dynamics and waves of neural activity during sleep in rat hippocampus.},
author = {Vogelstein, R Jacob and Mallik, Udayan and Vogelstein, Joshua T and Cauwenberghs, Gert},
doi = {10.1109/TNN.2006.883007},
issn = {1045-9227},
journal = {IEEE Transactions on Neural Networks},
keywords = {Action Potentials,Action Potentials: physiology,Biomimetics,Biomimetics: instrumentation,Biomimetics: methods,Computer Simulation,Computer-Aided Design,Electric Conductivity,Electronics,Equipment Design,Equipment Failure Analysis,Models,Nerve Net,Nerve Net: physiology,Neural Networks (Computer),Neurological,Neurons,Neurons: physiology,Silicon,Synaptic Transmission,Synaptic Transmission: physiology},
number = {1},
pages = {253--65},
pmid = {17278476},
title = {\href{https://www.researchgate.net/publication/6527229\_Dynamically\_reconfigurable\_silicon\_array\_of\_spiking\_neurons\_with\_conductance-based\_synapses?ev=prf\_pub}{Dynamically reconfigurable silicon array of spiking neurons with conductance-based synapses.}},
url = {https://www.researchgate.net/publication/6527229\_Dynamically\_reconfigurable\_silicon\_array\_of\_spiking\_neurons\_with\_conductance-based\_synapses?ev=prf\_pub},
volume = {18},
year = {2007}
}
@article{Vogelstein2009,
abstract = {As recent advances in calcium sensing technologies facilitate simultaneously imaging action potentials in neuronal populations, complementary analytical tools must also be developed to maximize the utility of this experimental paradigm. Although the observations here are fluorescence movies, the signals of interest--spike trains and/or time varying intracellular calcium concentrations--are hidden. Inferring these hidden signals is often problematic due to noise, nonlinearities, slow imaging rate, and unknown biophysical parameters. We overcome these difficulties by developing sequential Monte Carlo methods (particle filters) based on biophysical models of spiking, calcium dynamics, and fluorescence. We show that even in simple cases, the particle filters outperform the optimal linear (i.e., Wiener) filter, both by obtaining better estimates and by providing error bars. We then relax a number of our model assumptions to incorporate nonlinear saturation of the fluorescence signal, as well external stimulus and spike history dependence (e.g., refractoriness) of the spike trains. Using both simulations and in vitro fluorescence observations, we demonstrate temporal superresolution by inferring when within a frame each spike occurs. Furthermore, the model parameters may be estimated using expectation maximization with only a very limited amount of data (e.g., approximately 5-10 s or 5-40 spikes), without the requirement of any simultaneous electrophysiology or imaging experiments.},
author = {Vogelstein, Joshua T and Watson, Brendon O and Packer, Adam M and Yuste, Rafael and Jedynak, Bruno and Paninski, Liam},
doi = {10.1016/j.bpj.2008.08.005},
issn = {1542-0086},
journal = {Biophysical Journal},
keywords = {Animals,Biological,Calcium,Calcium: metabolism,Fluorescence,Inbred C57BL,Intracellular Space,Intracellular Space: metabolism,Mice,Models,Monte Carlo Method,Neurons,Neurons: cytology,Neurons: metabolism,Probability,Time Factors},
number = {2},
pages = {636--55},
pmid = {19619479},
title = {\href{https://www.researchgate.net/publication/26683205\_Spike\_inference\_from\_calcium\_imaging\_using\_sequential\_Monte\_Carlo\_methods}{Spike inference from calcium imaging using sequential Monte Carlo methods.}},
url = {https://www.researchgate.net/publication/26683205\_Spike\_inference\_from\_calcium\_imaging\_using\_sequential\_Monte\_Carlo\_methods},
volume = {97},
year = {2009}
}
@article{Paninski2010,
abstract = {State space methods have proven indispensable in neural data analysis. However, common methods for performing inference in state-space models with non-Gaussian observations rely on certain approximations which are not always accurate. Here we review direct optimization methods that avoid these approximations, but that nonetheless retain the computational efficiency of the approximate methods. We discuss a variety of examples, applying these direct optimization techniques to problems in spike train smoothing, stimulus decoding, parameter estimation, and inference of synaptic properties. Along the way, we point out connections to some related standard statistical methods, including spline smoothing and isotonic regression. Finally, we note that the computational methods reviewed here do not in fact depend on the state-space setting at all; instead, the key property we are exploiting involves the bandedness of certain matrices. We close by discussing some applications of this more general point of view, including Markov chain Monte Carlo methods for neural decoding and efficient estimation of spatially-varying firing rates.},
author = {Paninski, Liam and Ahmadian, Yashar and Ferreira, Daniel Gil and Koyama, Shinsuke and Rad, Kamiar R and Vidne, Michael and Vogelstein, Joshua and Wu, Wei},
doi = {10.1007/s10827-009-0179-x},
issn = {1573-6873},
journal = {Journal of Computational Neuroscience},
keywords = {Action Potentials,Action Potentials: physiology,Animals,Computer Simulation,Models,Neurological,Neurons,Neurons: physiology,Retinal Ganglion Cells,Retinal Ganglion Cells: physiology,Statistical,Synapses,Synapses: physiology},
number = {1-2},
pages = {107--26},
pmid = {19649698},
title = {\href{https://www.researchgate.net/publication/26712056\_A\_new\_look\_at\_state-space\_models\_for\_neural\_data?ev=prf\_pub}{A new look at State-Space Models for Neural Data}},
url = {https://www.researchgate.net/publication/26712056\_A\_new\_look\_at\_state-space\_models\_for\_neural\_data?ev=prf\_pub},
volume = {29},
year = {2010}
}
@article{Vogelstein2010,
abstract = {Fluorescent calcium indicators are becoming increasingly popular as a means for observing the spiking activity of large neuronal populations. Unfortunately, extracting the spike train of each neuron from a raw fluorescence movie is a nontrivial problem. This work presents a fast nonnegative deconvolution filter to infer the approximately most likely spike train of each neuron, given the fluorescence observations. This algorithm outperforms optimal linear deconvolution (Wiener filtering) on both simulated and biological data. The performance gains come from restricting the inferred spike trains to be positive (using an interior-point method), unlike the Wiener filter. The algorithm runs in linear time, and is fast enough that even when simultaneously imaging >100 neurons, inference can be performed on the set of all observed traces faster than real time. Performing optimal spatial filtering on the images further refines the inferred spike train estimates. Importantly, all the parameters required to perform the inference can be estimated using only the fluorescence data, obviating the need to perform joint electrophysiological and imaging calibration experiments.},
author = {Vogelstein, Joshua T and Packer, Adam M and Machado, Timothy A and Sippy, Tanya and Babadi, Baktash and Yuste, Rafael and Paninski, Liam},
doi = {10.1152/jn.01073.2009},
issn = {1522-1598},
journal = {Journal of Neurophysiology},
keywords = {Action Potentials,Algorithms,Calcium Signaling,Computer Simulation,Computer-Assisted,Fluorescence,Fluorescent Dyes,Fluorescent Dyes: analysis,Microscopy,Models,Neurological,Neurons,Neurons: physiology,Normal Distribution,Poisson Distribution,Signal Processing,Time Factors,Video},
number = {6},
pages = {3691--704},
pmid = {20554834},
title = {\href{https://www.researchgate.net/publication/44679723\_Fast\_nonnegative\_deconvolution\_for\_spike\_train\_inference\_from\_population\_calcium\_imaging}{Fast nonnegative deconvolution for spike train inference from population calcium imaging.}},
url = {https://www.researchgate.net/publication/44679723\_Fast\_nonnegative\_deconvolution\_for\_spike\_train\_inference\_from\_population\_calcium\_imaging},
volume = {104},
year = {2010}
}
@article{Mishchenko2011,
abstract = {Deducing the structure of neural circuits is one of the central problems of modern neuroscience. Recently-introduced calcium fluorescent imaging methods permit experimentalists to observe network activity in large populations of neurons, but these techniques provide only indirect observations of neural spike trains, with limited time resolution and signal quality. In this work we present a Bayesian approach for inferring neural circuitry given this type of imaging data. We model the network activity in terms of a collection of coupled hidden Markov chains, with each chain corresponding to a single neuron in the network and the coupling between the chains reflecting the network's connectivity matrix. We derive a Monte Carlo Expectation--Maximization algorithm for fitting the model parameters; to obtain the sufficient statistics in a computationally-efficient manner, we introduce a specialized blockwise-Gibbs algorithm for sampling from the joint activity of all observed neurons given the observed fluorescence data. We perform large-scale simulations of randomly connected neuronal networks with biophysically realistic parameters and find that the proposed methods can accurately infer the connectivity in these networks given reasonable experimental and computational constraints. In addition, the estimation accuracy may be improved significantly by incorporating prior knowledge about the sparseness of connectivity in the network, via standard L\$\_1\$ penalization methods.},
author = {Mishchenko, Yuriy and Vogelstein, Joshua T. and Paninski, Liam},
issn = {1941-7330},
journal = {The Annals of Applied Statistics},
keywords = {Metropolis–Hastings,Sequential Monte Carlo,generalized linear model,point process,spike train data},
language = {EN},
number = {2B},
pages = {1229--1261},
publisher = {Institute of Mathematical Statistics},
title = {\href{http://projecteuclid.org/euclid.aoas/1310562720}{A Bayesian approach for inferring neuronal connectivity from calcium fluorescent imaging data}},
volume = {5},
year = {2011}
}
@article{Hofer2011,
abstract = {Neuronal responses during sensory processing are influenced by both the organization of intracortical connections and the statistical features of sensory stimuli. How these intrinsic and extrinsic factors govern the activity of excitatory and inhibitory populations is unclear. Using two-photon calcium imaging in vivo and intracellular recordings in vitro, we investigated the dependencies between synaptic connectivity, feature selectivity and network activity in pyramidal cells and fast-spiking parvalbumin-expressing (PV) interneurons in mouse visual cortex. In pyramidal cell populations, patterns of neuronal correlations were largely stimulus-dependent, indicating that their responses were not strongly dominated by functionally biased recurrent connectivity. By contrast, visual stimulation only weakly modified co-activation patterns of fast-spiking PV cells, consistent with the observation that these broadly tuned interneurons received very dense and strong synaptic input from nearby pyramidal cells with diverse feature selectivities. Therefore, feedforward and recurrent network influences determine the activity of excitatory and inhibitory ensembles in fundamentally different ways.},
author = {Hofer, Sonja B and Ko, Ho and Pichler, Bruno and Vogelstein, Joshua and Ros, Hana and Zeng, Hongkui and Lein, Ed and Lesica, Nicholas A and Mrsic-Flogel, Thomas D},
doi = {10.1038/nn.2876},
issn = {1546-1726},
journal = {Nature Neuroscience},
keywords = {Analysis of Variance,Animals,Calcium,Calcium: metabolism,Evoked Potentials,Excitatory Postsynaptic Potentials,Excitatory Postsynaptic Potentials: genetics,Inbred C57BL,Mice,Neural Inhibition,Neural Inhibition: physiology,Neurons,Neurons: classification,Neurons: physiology,Organic Chemicals,Organic Chemicals: metabolism,Parvalbumins,Parvalbumins: genetics,Patch-Clamp Techniques,Photic Stimulation,Photic Stimulation: methods,Reaction Time,Reaction Time: physiology,Statistics as Topic,Synapses,Synapses: physiology,Transgenic,Visual,Visual Cortex,Visual Cortex: cytology,Visual Pathways,Visual Pathways: physiology,Visual: genetics,Visual: physiology},
number = {8},
pages = {1045--52},
pmid = {21765421},
publisher = {Nature Publishing Group, a division of Macmillan Publishers Limited. All Rights Reserved.},
shorttitle = {Nat Neurosci},
title = {\href{http://www.nature.com/neuro/journal/v14/n8/abs/nn.2876.html#close}{Differential connectivity and response dynamics of excitatory and inhibitory neurons in visual cortex.}},
volume = {14},
year = {2011}
}
@article{Vogelstein2011b,
abstract = {The "mind-brain supervenience" conjecture suggests that all mental properties are derived from the physical properties of the brain. To address the question of whether the mind supervenes on the brain, we frame a supervenience hypothesis in rigorous statistical terms. Specifically, we propose a modified version of supervenience (called $\epsilon$-supervenience) that is amenable to experimental investigation and statistical analysis. To illustrate this approach, we perform a thought experiment that illustrates how the probabilistic theory of pattern recognition can be used to make a one-sided determination of $\epsilon$-supervenience. The physical property of the brain employed in this analysis is the graph describing brain connectivity (i.e., the brain-graph or connectome). $\epsilon$-supervenience allows us to determine whether a particular mental property can be inferred from one's connectome to within any given positive misclassification rate, regardless of the relationship between the two. This may provide further motivation for cross-disciplinary research between neuroscientists and statisticians.},
author = {Vogelstein, Joshua T and Vogelstein, R Jacob and Priebe, Carey E},
doi = {10.1038/srep00100},
issn = {2045-2322},
journal = {Scientific Reports},
keywords = {Brain,Brain: physiology,Humans,Mental Processes,Probability},
language = {en},
pages = {100},
pmid = {22355618},
publisher = {Nature Publishing Group},
title = {\href{https://www.researchgate.net/publication/45889003\_Are\_mental\_properties\_supervenient\_on\_brain\_properties}{Are mental properties supervenient on brain properties?}},
url = {https://www.researchgate.net/publication/45889003\_Are\_mental\_properties\_supervenient\_on\_brain\_properties},
volume = {1},
year = {2011}
}
@article{Gray2012,
abstract = {This article presents a Novemberel, tightly integrated pipeline for estimating a connectome. The pipeline utilizes magnetic resonance (MR) imaging (MRI) data to produce a high-level estimate of the structural connectivity in the human brain. The MR connectome automated pipeline (MRCAP) is efficient, and its modular construction allows researchers to modify algorithms to meet their specific requirements. The pipeline has been validated, and more than 200 connectomes have been processed and analyzed to date.},
author = {Gray, William R and Bogovic, John A and Vogelstein, Joshua T and Landman, Bennett A and Prince, Jerry L and Vogelstein, R J},
doi = {10.1109/MPUL.2011.2181023},
issn = {2154-2287},
journal = {IEEE Pulse},
keywords = {Algorithms,Brain,Brain: anatomy \& histology,Brain: physiology,Databases,Diagnostic Techniques,Factual,Humans,Magnetic Resonance Imaging,Nerve Net,Nerve Net: anatomy \& histology,Nerve Net: physiology,Neurological},
number = {2},
pages = {42--8},
pmid = {22481745},
shorttitle = {Pulse, IEEE},
title = {\href{https://www.researchgate.net/publication/223963176\_Magnetic\_resonance\_connectome\_automated\_pipeline\_an\_overview}{Magnetic resonance connectome automated pipeline: an overview.}},
url = {https://www.researchgate.net/publication/223963176\_Magnetic\_resonance\_connectome\_automated\_pipeline\_an\_overview},
volume = {3},
year = {2012}
}
@article{Roberts2012,
abstract = {New DNA sequencing methods will soon make it possible to identify all germline variants in any individual at a reasonable cost. However, the ability of whole-genome sequencing to predict predisposition to common diseases in the general population is unknown. To estimate this predictive capacity, we use the concept of a "genometype." A specific genometype represents the genomes in the population conferring a specific level of genetic risk for a specified disease. Using this concept, we estimated the maximum capacity of whole-genome sequencing to identify individuals at clinically significant risk for 24 different diseases. Our estimates were derived from the analysis of large numbers of monozygotic twin pairs; twins of a pair share the same genometype and therefore identical genetic risk factors. Our analyses indicate that (i) for 23 of the 24 diseases, most of the individuals will receive negative test results; (ii) these negative test results will, in general, not be very informative, because the risk of developing 19 of the 24 diseases in those who test negative will still be, at minimum, 50 to 80\% of that in the general population; and (iii) on the positive side, in the best-case scenario, more than 90\% of tested individuals might be alerted to a clinically significant predisposition to at least one disease. These results have important implications for the valuation of genetic testing by industry, health insurance companies, public policy-makers, and consumers.},
author = {Roberts, Nicholas J and Vogelstein, Joshua T and Parmigiani, Giovanni and Kinzler, Kenneth W and Vogelstein, Bert and Velculescu, Victor E},
doi = {10.1126/scitranslmed.3003380},
issn = {1946-6242},
journal = {Science Translational Medicine},
keywords = {DNA,DNA: trends,Female,Genetic,Genetic Predisposition to Disease,Genome,High-Throughput Nucleotide Sequencing,High-Throughput Nucleotide Sequencing: trends,Human,Humans,Individualized Medicine,Individualized Medicine: methods,Individualized Medicine: trends,Male,Mathematical Concepts,Models,Monozygotic,Monozygotic: genetics,Risk Factors,Sequence Analysis,Translational Medical Research,Twins},
number = {133},
pages = {133ra58},
pmid = {22472521},
title = {\href{https://www.researchgate.net/publication/223985064\_The\_predictive\_capacity\_of\_personal\_genome\_sequencing}{The predictive capacity of personal genome sequencing.}},
url = {https://www.researchgate.net/publication/223985064\_The\_predictive\_capacity\_of\_personal\_genome\_sequencing},
volume = {4},
year = {2012}
}
@article{Fishkind2013,
abstract = {For random graphs distributed according to a stochastic block model, we consider the inferential task of partitioning vertices into blocks using spectral techniques. Spectral partitioning using the normalized Laplacian and the adjacency matrix have both been shown to be consistent as the number of vertices tend to infinity. Importantly, both procedures require that the number of blocks and the rank of the communication probability matrix be known, even as the rest of the parameters may be unknown. In this paper, we prove that the (suitably modified) adjacency-spectral partitioning procedure, requiring only an upper bound on the rank of the communication probability matrix, is consistent. Indeed, this result demonstrates a robustness to model mis-specification; an overestimate of the rank may impose a moderate performance penalty, but the procedure is still consistent. Furthermore, we extend this procedure to the setting where adjacencies may have multiple modalities and we allow for either directed or und...},
author = {Fishkind, Donniell E. and Sussman, Daniel L. and Tang, Minh and Vogelstein, Joshua T. and Priebe, Carey E.},
doi = {10.1137/120875600},
issn = {0895-4798},
journal = {SIAM Journal on Matrix Analysis and Applications},
keywords = {15A18,62F12,62F35,adjacency matrix,spectral partition,stochastic block model},
language = {en},
number = {1},
pages = {23--39},
publisher = {Society for Industrial and Applied Mathematics},
title = {\href{https://www.researchgate.net/publication/224904689\_Consistent\_adjacency-spectral\_partitioning\_for\_the\_stochastic\_blockmodel\_when\_the\_model\_parameters\_are\_unknown}{Consistent Adjacency-Spectral Partitioning for the Stochastic Block Model When the Model Parameters Are Unknown}},
url = {https://www.researchgate.net/publication/224904689\_Consistent\_adjacency-spectral\_partitioning\_for\_the\_stochastic\_blockmodel\_when\_the\_model\_parameters\_are\_unknown},
volume = {34},
year = {2013}
}
@article{Dai2012,
author = {Dai, Dai and He, Huiguang and Vogelstein, Joshua T. and Hou, Zengguang},
doi = {10.1007/s00138-012-0462-0},
issn = {0932-8092},
journal = {Machine Vision and Applications},
number = {7},
pages = {1445--1457},
title = {\href{https://www.researchgate.net/publication/257334077\_Accurate\_prediction\_of\_AD\_patients\_using\_cortical\_thickness\_networks?ev=prf\_pub}{Accurate prediction of AD patients using cortical thickness networks}},
url = {https://www.researchgate.net/publication/257334077\_Accurate\_prediction\_of\_AD\_patients\_using\_cortical\_thickness\_networks?ev=prf\_pub},
volume = {24},
year = {2012}
}
@article{Priebe2013,
abstract = {We demonstrate a meaningful prospective power analysis for an (admittedly idealized) illustrative connectome inference task. Modeling neurons as vertices and synapses as edges in a simple random graph model, we optimize the trade-off between the number of (putative) edges identified and the accuracy of the edge identification procedure. We conclude that explicit analysis of the quantity/quality trade-off is imperative for optimal neuroscientific experimental design. In particular, identifying edges faster/more cheaply, but with more error, can yield superior inferential performance. We demonstrate a meaningful prospective power analysis for an (admittedly idealized) illustrative connectome inference task. Modeling neurons as vertices and synapses as edges in a simple random graph model, we optimize the trade-off between the number of (putative) edges identified and the accuracy of the edge identification procedure. We conclude that explicit analysis of the quantity/quality trade-off is imperative for optimal neuroscientific experimental design. In particular, identifying edges faster/more cheaply, but with more error, can yield superior inferential performance.},
author = {Priebe, Carey E. and Vogelstein, Joshua and Bock, Davi},
doi = {10.1080/03610926.2011.630768},
issn = {0361-0926},
journal = {Communications in Statistics - Theory and Methods},
number = {19},
pages = {3455--3462},
publisher = {Taylor \& Francis},
title = {\href{https://www.researchgate.net/publication/51941784\_Optimizing\_the\_quantityquality\_trade-off\_in\_connectome\_inference}{Optimizing the Quantity/Quality Trade-Off in Connectome Inference}},
url = {https://www.researchgate.net/publication/51941784\_Optimizing\_the\_quantityquality\_trade-off\_in\_connectome\_inference},
volume = {42},
year = {2013}
}
@article{Craddock2013,
abstract = {At macroscopic scales, the human connectome comprises anatomically distinct brain areas, the structural pathways connecting them and their functional interactions. Annotation of phenotypic associations with variation in the connectome and cataloging of neurophenotypes promise to transform our understanding of the human brain. In this Review, we provide a survey of magnetic resonance imaging–based measurements of functional and structural connectivity. We highlight emerging areas of development and inquiry and emphasize the importance of integrating structural and functional perspectives on brain architecture.},
author = {Craddock, R Cameron and Jbabdi, Saad and Yan, Chao-Gan and Vogelstein, Joshua T and Castellanos, F Xavier and {Di Martino}, Adriana and Kelly, Clare and Heberlein, Keith and Colcombe, Stan and Milham, Michael P},
doi = {10.1038/nmeth.2482},
issn = {1548-7105},
journal = {Nature Methods},
keywords = {Brain,Brain: cytology,Brain: physiology,Connectome,Humans,Magnetic Resonance Imaging,Magnetic Resonance Imaging: methods,Phenotype},
number = {6},
pages = {524--39},
pmid = {23722212},
publisher = {Nature Publishing Group, a division of Macmillan Publishers Limited. All Rights Reserved.},
shorttitle = {Nat Meth},
title = {\href{https://www.researchgate.net/publication/236976801\_Imaging\_human\_connectomes\_at\_the\_macroscale}{Imaging human connectomes at the macroscale.}},
url = {https://www.researchgate.net/publication/236976801\_Imaging\_human\_connectomes\_at\_the\_macroscale},
volume = {10},
year = {2013}
}
@article{Vogelstein2015,
abstract = {Quadratic assignment problems (QAPs) arise in a wide variety of domains, ranging from operations research to graph theory to computer vision to neuroscience. In the age of big data, graph valued data is becoming more prominent, and with it, a desire to run algorithms on ever larger graphs. Because QAP is NP-hard, exact algorithms are intractable. Approximate algorithms necessarily employ an accuracy/efficiency trade-off. We developed a fast approximate quadratic assignment algorithm (FAQ). FAQ finds a local optima in (worst case) time cubic in the number of vertices, similar to other approximate QAP algorithms. We demonstrate empirically that our algorithm is faster and achieves a lower objective value on over 80\% of the suite of QAP benchmarks, compared with the previous state-of-the-art. Applying the algorithms to our motivating example, matching C. elegans connectomes (brain-graphs), we find that FAQ achieves the optimal performance in record time, whereas none of the others even find the optimum.},
archivePrefix = {arXiv},
arxivId = {1112.5507},
author = {Vogelstein, Joshua T. and Conroy, John M. and Lyzinski, Vince and Podrazik, Louis J. and Kratzer, Steven G. and Harley, Eric T. and Fishkind, Donniell E. and Vogelstein, R. Jacob and Priebe, Carey E.},
journal = {PLoS One},
volume = {10},
issue = {4},
pages = {e0121002},
title = {\href{http://dx.doi.org/10.1371/journal.pone.0121002}{Fast Approximate Quadratic Programming for Graph Matching}},
url = {http://dx.doi.org/10.1371/journal.pone.0121002},
doi = {10.1371/journal.pone.0121002},
year = {2015}
}
@article{Kazhdan2013,
archivePrefix = {arXiv},
arxivId = {1310.0041},
author = {Kazhdan, Michael and Burns, Randal and Kasthuri, Bobby and Lichtman, Jeff and Vogelstein, Jacob and Vogelstein, Joshua},
eprint = {1310.0041},
journal = {arXiv},
volume ={1310.0041},
title = {\href{http://arxiv.org/abs/1310.0041}{Gradient-Domain Processing for Large EM Image Stacks}},
url = {http://arxiv.org/abs/1310.0041},
year = {2013}
}
@article{Chen2015a,
abstract = {For random graphs distributed according to stochastic blockmodels, a special case of latent position graphs, adjacency spectral embedding followed by appropriate vertex classification is asymptotically Bayes optimal. Importantly, this approach requires knowledge of the model dimension. In this paper, we propose a sparse representation vertex classifier which does not require information about the model dimension. This classifier represents a test vertex as a sparse linear combination of the vertices in the training set and uses the recovered coefficients to classify the test vertex. We demonstrate that the sparse representation classifier can predict vertex labels with higher accuracy than adjacency spectral embedding approaches via both a simulation study and real data experiments considering the Caenorhabditis elegans neuronal network and the Enron communication network. Our results demonstrate the robustness of our proposed vertex classifier when the model dimension is unknown.},
archivePrefix = {arXiv},
arxivId = {1311.5954},
author = {Chen, Li and Vogelstein, Joshua and Priebe, Carey},
eprint = {1311.5954},
journal = {IEEE Pattern Analysis and Machine Intelligence (in press)},
doi={10.1109/TPAMI.2015.2456913},
volume = {PP},
pages = {27},
title = {\href{http://arxiv.org/abs/1311.5954}{Robust Vertex Classification}},
url = {http://arxiv.org/abs/1311.5954},
year = {2015}
}
@article{Banerjee2013,
abstract = {An extremely common bottleneck encountered in statistical learning algorithms is inversion of huge covariance matrices, examples being in evaluating Gaussian likelihoods for a large number of data points. We propose general parallel algorithms for inverting positive definite matrices, which are nearly rank deficient. Such matrix inversions are needed in Gaussian process computations, among other settings, and remain a bottleneck even with the increasing literature on low rank approximations. We propose a general class of algorithms for parallelizing computations to dramatically speed up computation time by orders of magnitude exploiting multicore architectures. We implement our algorithm on a cloud computing platform, providing pseudo and actual code. The algorithm can be easily implemented on any multicore parallel computing resource. Some illustrations are provided to give a flavor for the gains and what becomes possible in freeing up this bottleneck.},
archivePrefix = {arXiv},
arxivId = {1312.1869},
author = {Banerjee, Anjishnu and Vogelstein, Joshua and Dunson, David},
eprint = {1312.1869},
journal = {arXiv},
volume = {1312.1869},
pages = {17},
title = {\href{http://arxiv.org/abs/1312.1869}{Parallel inversion of huge covariance matrices}},
url = {http://arxiv.org/abs/1312.1869},
year = {2013}
}
@article{Lyzinski2014,
archivePrefix = {arXiv},
arxivId = {1401.3813},
author = {Lyzinski, Vince and Adali, Sancar and Vogelstein, Joshua T. and Park, Youngser and Priebe, Carey E.},
eprint = {1401.3813},
journal = {arXiv},
volume = {1401.3813},
title = {\href{http://arxiv.org/abs/1401.3813}{Seeded Graph Matching Via Joint Optimization of Fidelity and Commensurability}},
url = {http://arxiv.org/abs/1401.3813},
year = {2014}
}
@article{Lyzinski2015a,
abstract = {We present a parallelized bijective graph matching algorithm that leverages seeds and is designed to match very large graphs. Our algorithm combines spectral graph embedding with existing state-of-the-art seeded graph matching procedures. We justify our approach by proving that modestly correlated, large stochastic block model random graphs are correctly matched utilizing very few seeds through our divide-and-conquer procedure.},
archivePrefix = {arXiv},
arxivId = {1310.1297},
journal = {arXiv},
volume={1310.1297},
author = {Lyzinski, Vince and Sussman, Daniel L. and Fishkind, Donniell E. and Pao, Henry and Chen, Li and Vogelstein, Joshua T. and Park, Youngser and Priebe, Carey E.},
eprint = {1310.1297},
doi={10.1016/j.parco.2015.03.004},
title = {\href{http://arxiv.org/abs/1310.1297}{Spectral Clustering for Divide-and-Conquer Graph Matching}},
url = {http://arxiv.org/abs/1310.1297},
year = {2015}
}
@article{Roncal2014,
archivePrefix = {arXiv},
arxivId = {1403.3724},
author = {Roncal, William Gray and Kaynig-Fittkau, Verena and Kasthuri, Narayanan and Berger, Daniel and Vogelstein, Joshua T. and Fernandez, Lindsey R. and Lichtman, Jeff W and Vogelstein, R. Jacob and Pfister, Hanspeter and Hager, Gregory D.},
eprint = {1403.3724},
title = {\href{http://arxiv.org/abs/1403.3724}{Volumetric Exploitation of Synaptic Information using Context Localization and Evaluation}},
journal = {arXiv},
volume = {1403.3724},
url = {http://arxiv.org/abs/1403.3724},
year = {2014}
}
@article{Lyzinski2014a,
archivePrefix = {arXiv},
arxivId = {1405.3133},
author = {Lyzinski, Vince and Fishkind, Donniell and Fiori, Marcelo and Vogelstein, Joshua T. and Priebe, Carey E. and Sapiro, Guillermo},
eprint = {1405.3133},
journal = {arXiv},
volume = {1405.3133},
title = {\href{http://arxiv.org/abs/1405.3133}{Graph Matching: Relax at Your Own Risk}},
url = {http://arxiv.org/abs/1405.3133},
year = {2014}
}
@article{Durante2014,
abstract = {Collections of networks are available in many research fields. In connectomic applications, inter-connections among brain regions are collected from each patient, with interest focusing on studying shared structure and the population distribution of deviations across individuals. Current methods focus on reducing network data to features prior to statistical analysis, while we propose a fully generative Bayesian nonparametric approach for modeling the population distribution of network-valued data. The joint distribution of the edges follows a multivariate Bernoulli distribution, with transformed edge probability vectors expressed as the sum of a shared similarity vector and a class-specific deviation modeled via flexible low-rank factorization exploiting the network structure. The formulation is provably flexible, leads to a simple and computationally efficient Gibbs sampler, and provides a framework for clustering graph-valued data, while inferring a cluster-specific rank. We discuss theoretical properties and illustrate the performance in simulations and application to human brain network data.},
archivePrefix = {arXiv},
arxivId = {1406.7851},
author = {Durante, Daniele and Dunson, David B. and Vogelstein, Joshua T.},
eprint = {1406.7851},
journal = {arXiv},
volume = {1406.7851},
title = {\href{http://arxiv.org/abs/1406.7851}{Nonparametric Bayes Modeling of Populations of Networks}},
url = {http://arxiv.org/abs/1406.7851},
year = {2014}
}
@article{Carlson2013b,
archivePrefix = {arXiv},
arxivId = {1304.0542},
author = {Carlson, David E. and Vogelstein, Joshua T. and Wu, Qisong and Lian, Wenzhao and Zhou, Mingyuan and Stoetzner, Colin R. and Kipke, Daryl and Weber, Douglas and Dunson, David B. and Carin, Lawrence},
eprint = {1304.0542},
title = {\href{http://arxiv.org/abs/1304.0542}{Multichannel Electrophysiological Spike Sorting via Joint Dictionary Learning \& Mixture Modeling}},
url = {http://arxiv.org/abs/1304.0542},
journal = {IEEE Transactions on Biomedical Engineering},
volume = {61},
number = {1},
pages = {41--54},
year = {2014}
}
@article{Vogelstein2015b,
abstract = {We develop a formalism to address statistical pattern recognition of graph valued data. Of particular interest is the case of all graphs having the same number of uniquely labeled vertices. When the vertex labels are latent, such graphs are called shuffled graphs. Our formalism provides insight to trivially answer a number of open statistical questions including: (i) under what conditions does shuffling the vertices degrade classification performance and (ii) do universally consistent graph classifiers exist? The answers to these questions lead to practical heuristic algorithms with state-of-the-art finite sample performance, in agreement with our theoretical asymptotics.},
archivePrefix = {arXiv},
arxivId = {1112.5506},
author = {Vogelstein, Joshua T. and Priebe, Carey E.},
eprint = {1112.5506},
title = {\href{http://link.springer.com/article/10.1007%2Fs00357-015-9170-6}{Shuffled Graph Classification: Theory and Connectome Applications}},
url = {http://arxiv.org/abs/1112.5506},
journal = {Journal of Classification},
year = {2015},
volume=32,
issue=1,
pages = {3--20}
}
@article{Vogelstein2014a,
abstract = {A single nervous system can generate many distinct motor patterns. Identifying which neurons and circuits control which behaviors has been a laborious piecemeal process, usually for one observer-defined behavior at a time. We present a fundamentally different approach to neuron-behavior mapping. We optogenetically activated 1054 identified neuron lines in Drosophila larvae and tracked the behavioral responses from 37,780 animals. Application of multiscale unsupervised structure learning methods to the behavioral data enabled us to identify 29 discrete, statistically distinguishable, observer-unbiased behavioral phenotypes. Mapping the neural lines to the behavior(s) they evoke provides a behavioral reference atlas for neuron subsets covering a large fraction of larval neurons. This atlas is a starting point for connectivity- and activity-mapping studies to further investigate the mechanisms by which neurons mediate diverse behaviors.},
author = {Vogelstein, Joshua T and Park, Youngser and Ohyama, Tomoko and Kerr, Rex A and Truman, James W and Priebe, Carey E and Zlatic, Marta},
doi = {10.1126/science.1250298},
issn = {1095-9203},
journal = {Science (New York, N.Y.)},
keywords = {Animal,Animals,Artificial Intelligence,Behavior,Brain,Brain Mapping,Brain: physiology,Drosophila melanogaster,Drosophila melanogaster: cytology,Drosophila melanogaster: physiology,Larva,Larva: physiology,Locomotion,Motor Neurons,Motor Neurons: physiology,Movement,Neurons,Neurons: physiology,Optogenetics},
number = {6182},
pages = {386--92},
pmid = {24674869},
title = {\href{https://www.researchgate.net/publication/261184543\_Discovery\_of\_Brainwide\_Neural-Behavioral\_Maps\_via\_Multiscale\_Unsupervised\_Structure\_Learning}{Discovery of brainwide neural-behavioral maps via multiscale unsupervised structure learning.}},
url = {https://www.researchgate.net/publication/261184543\_Discovery\_of\_Brainwide\_Neural-Behavioral\_Maps\_via\_Multiscale\_Unsupervised\_Structure\_Learning},
volume = {344},
year = {2014}
}
@article{Sweeney2014,
abstract = {Machine learning is a popular method for mining and analyzing large collections of medical data. We focus on a particular problem from medical research, supervised multiple sclerosis (MS) lesion segmentation in structural magnetic resonance imaging (MRI). We examine the extent to which the choice of machine learning or classification algorithm and feature extraction function impacts the performance of lesion segmentation methods. As quantitative measures derived from structural MRI are important clinical tools for research into the pathophysiology and natural history of MS, the development of automated lesion segmentation methods is an active research field. Yet, little is known about what drives performance of these methods. We evaluate the performance of automated MS lesion segmentation methods, which consist of a supervised classification algorithm composed with a feature extraction function. These feature extraction functions act on the observed T1-weighted (T1-w), T2-weighted (T2-w) and fluid-attenuated inversion recovery (FLAIR) MRI voxel intensities. Each MRI study has a manual lesion segmentation that we use to train and validate the supervised classification algorithms. Our main finding is that the differences in predictive performance are due more to differences in the feature vectors, rather than the machine learning or classification algorithms. Features that incorporate information from neighboring voxels in the brain were found to increase performance substantially. For lesion segmentation, we conclude that it is better to use simple, interpretable, and fast algorithms, such as logistic regression, linear discriminant analysis, and quadratic discriminant analysis, and to develop the features to improve performance.},
author = {Sweeney, Elizabeth M and Vogelstein, Joshua T and Cuzzocreo, Jennifer L and Calabresi, Peter A and Reich, Daniel S and Crainiceanu, Ciprian M and Shinohara, Russell T},
title = {\href{http://journals.plos.org/plosone/article?id=10.1371/journal.pone.0095753}{A Comparison of Supervised Machine Learning Algorithms and Feature Vectors for MS Lesion Segmentation Using Multimodal Structural MRI}},
doi = {10.1371/journal.pone.0095753},
isbn = {10.1371/journal.pone.0095753},
issn = {1932-6203},
journal = {PLoS ONE},
volume = {9},
issue = {4},
pages = {e95753},
year = {2014}
}
@article{Priebe2014a.
abstract = {Statistical inference on graphs is a burgeoning field in the applied and theoretical statistics communities, as well as throughout the wider world of science, engineering, business, etc. In many applications, we are faced with the reality of errorfully observed graphs. That is, the existence of an edge between two vertices is based on some imperfect assessment. In this paper, we consider a graph G = (V,E). We wish to perform an inference task - the it surrogate inference task considered here is "vertex classification". However, we do not observe G; rather, for each potential edge uv in Vchoose2 we observe an "edge-feature" which we use to classify uv as edge/not-edge. Thus we it errorfully observe G when we observe the graph widetildeG = (V,widetildeE). Moreover, we face a quantity/quality trade-off regarding the edge-features we observe - more informative edge-features are more expensive, and hence the number of potential edges that can be assessed decreases with the quality of the edge-features. We derive the optimal quantity/quality operating point for subsequent graph inference in the face of this trade-off.},
archivePrefix = {arXiv},
rxivId = {arXiv:1211.3601v4},
author = {Priebe, Carey E and Sussman, David L and Tang, M and Vogelstein, Joshua T},
journal = {Journal of Computational and Graphical Statistics},
title = {\href{http://www.tandfonline.com/doi/full/10.1080/10618600.2014.951049}{Statistical inference on errorfully observed graphs}},
year = {2014}
}
@article{Roncal2015b,
abstract = {Reconstructing a map of neuronal connectivity is a critical challenge in contemporary neuroscience. Recent advances in high-throughput electron microscopy have produced massive images of nanoscale brain tissue for the first time. This resolution allows for individual neurons and their synaptic connections to be directly observed. Manually tracing each neuronal process at this scale is unmanageable, and therefore researchers are developing automated image processing modules. Thus far, state-of-the-art algorithms focus only on the solution to a particular task (e.g., neuron segmentation or synapse identification). 
We have created the first fully automated images-to-graphs pipeline (i.e., a pipeline that begins with an imaged volume of neural tissue and produces a brain graph without any human interaction). To evaluate overall performance and select the best parameters and methods, we also develop a metric to assess the quality of the output graphs. We demonstrate our pipeline by selecting a set of algorithms and parameters, and search possible operating points to identify the best available brain graph. New algorithms can be easily integrated into our scalable pipeline, and used to improve results and facilitate analysis.},
author = {Gray, William R and Kleissas, Dean M and Vogelstein, Joshua T and Manavalan, Priya and Burns, Randal R and Vogelstein, R Jacob and Priebe, Carey E and Chevillet, Mark A and Hager, Gregory D},
journal = {arXiv},
volume = {1411.6880},
title = {\href{http://arxiv.org/abs/1411.6880}{An Automated Images-to-Graphs Pipeline for High Resolution Connectomics}},
year = {2015}
//}
